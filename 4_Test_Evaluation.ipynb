{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Performances\n",
    "\n",
    "Notebook to analyse test performances, including :\n",
    "- full-disk level performances\n",
    "- patch/sector level performances\n",
    "- center vs. limb pathes performances\n",
    "- performances on windows where the activity differes from the previous one (AC-windows)\n",
    "- performances on windows where the activity is the same as the previous one (NC-windows)\n",
    "- persistent relative metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLAB = False\n",
    "\n",
    "if COLAB : \n",
    "  configSetup = {\n",
    "      'COLAB'           : 'True',\n",
    "      'PATH_ROOT_DRIVE' : '/content/drive/MyDrive/Projects/Forecast',\n",
    "      'PATH_ROOT_LOCAL' : '/content/session',\n",
    "      'PATH_SUNDL'      : '/content/sundl',\n",
    "      'PATH_PROJECT'    : '/content/flare_limits_pcnn'\n",
    "  }\n",
    "  !git clone https://github.com/gfrancisco20/sundl.git\n",
    "  !git clone https://github.com/gfrancisco20/flare_limits_pcnn.git\n",
    "  import sys\n",
    "  import re\n",
    "  sys.path.append(configSetup['PATH_SUNDL'])\n",
    "  sys.path.append(configSetup['PATH_PROJECT'])\n",
    "  configFile = f'{configSetup[\"PATH_PROJECT\"]}/config.py'\n",
    "  with open(configFile, 'r') as file:\n",
    "    content = file.read()\n",
    "  for constant in configSetup.keys():\n",
    "    content = re.sub(re.compile(f'{constant} = .*'), f'{constant} = \\'{configSetup[constant]}\\'', content)\n",
    "  with open(configFile, 'w') as file:\n",
    "    file.write(content)\n",
    "   \n",
    "from config import *\n",
    "if COLAB:\n",
    "  from sundl.utils.colab import mountDrive\n",
    "  # mouting drive content in session on colab\n",
    "  mountDrive()\n",
    "  \n",
    "# you must request the prediction  files  or recompute  them with folder 3  to run this  notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import dill as pickle\n",
    "\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sundl.utils.data import read_Dataframe_With_Dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER = PATH_RES/'Classification_PCNN_224x448x3xCV05_2024_03_28__0' #Classification_PCNN_224x448x3xCV05_2024_03_28__0'  \n",
    "\n",
    "modelDict = {\n",
    "  'C+_mpf_Persistent_24'                                        : 'C+_Persistent',\n",
    "  'C+_mpf_jpg_PTx8_RtdXall_EquiC_AW1e5D1e4_blos_24'          : 'C+_PCNN_Blos', #\n",
    "  'C+_mpf_jpg_PTx8_RtdXall_EquiC_AW1e5D1e4_0193x0211x0094_24': 'C+_PCNN_EUV',\n",
    "  'M+_mpf_Persistent_24'                                        : 'M+_Persistent',\n",
    "  'M+_mpf_jpg_PTx8_RtdXall_LowC2_AW1e5D1e4_0193x0211x0094_24': 'M+_PCNN_EUV',\n",
    "  'M+_mpf_jpg_PTx8_RtdXall_LowC2_AW1e5D1e4_blos_24'          : 'M+_PCNN_Blos',\n",
    "  'C+_PCNN_Both_Max'                                       : 'C+_PCNN_Both_Max',\n",
    "  'M+_PCNN_Both_Max'                                       : 'M+_PCNN_Both_Max', \n",
    "  'C+_PCNN_Both_Avg'                                       : 'C+_PCNN_Both_Avg',\n",
    "  'M+_PCNN_Both_Avg'                                       : 'M+_PCNN_Both_Avg' \n",
    "}\n",
    "\n",
    "modelDictRev = {modelDict[oldName] : oldName for oldName in modelDict.keys()}\n",
    "\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Disk Performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from config import F_PATH_PREDS_MODEL\n",
    "fdPredictions = {}\n",
    "for modelNameFull in modelDict.keys():\n",
    "  modelName = modelNameFull # modelDict[modelNameFull]\n",
    "  pathPredFd_withLabels = F_PATH_PREDS_MODEL(F_PATH_PREDS(FOLDER), modelName, 'fd', True)\n",
    "  if pathPredFd_withLabels.exists():\n",
    "    fdPredictions[modelName] = read_Dataframe_With_Dates(pathPredFd_withLabels)\n",
    "  else:\n",
    "    pathPredFd = F_PATH_PREDS_MODEL(F_PATH_PREDS(FOLDER), modelName, 'fd', False)\n",
    "    if pathPredFd.exists():\n",
    "      fdPredictions[modelName] = read_Dataframe_With_Dates(pathPredFd)\n",
    "      fdPredictions[modelName]['histo'] = fdPredictions[modelName]['label'].rolling(window = f'{24}H',\n",
    "                                        closed = 'left', # min_periods = int(input_lag)\n",
    "                                        ).apply(\n",
    "                                          lambda x: x[0])\n",
    "      fdPredictions[modelName]['change'] = fdPredictions[modelName]['histo'] != fdPredictions[modelName]['label']\n",
    "      if 'Persistent' in modelName:\n",
    "        fdPredictions[modelName]['pred'] = fdPredictions[modelName]['histo']\n",
    "      else:\n",
    "        fdPredictions[modelName].index = fdPredictions[modelName].index + pd.DateOffset(hours= -24)\n",
    "      fdPredictions[modelName].to_csv(pathPredFd_withLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from utilsTest import fullDiskPerformance\n",
    "\n",
    "startingDates = [datetime.datetime(2020,1,28)]\n",
    "filterNames   = ['all','windowChanging', 'windowConstant']\n",
    "includeFolds  = True\n",
    "\n",
    "perfTest = fullDiskPerformance(fdPredictions, \n",
    "                               startingDates, \n",
    "                               filterNames, \n",
    "                               includeFolds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = perfTest.copy()[perfTest.modelFdId == 'avg']\n",
    "viz = viz[viz['startingDate']==viz['startingDate'].min()]\n",
    "\n",
    "col = ['filter','tss', 'hss', 'mcc', 'f1',  'recall', 'far', 'bal_pos', 'switch_rate', 'fssp', 'fssr' ,'acc_w']\n",
    "\n",
    "# viz[viz['filter']=='all'].sort_values(['tss'], ascending = False)[col]\n",
    "\n",
    "modelsTab = ['C+_Persistent' ,'C+_PCNN_EUV', 'C+_PCNN_Blos', #'C+_PCNN_Both_Avg', 'C+_PCNN_Both_Max',\n",
    "             'M+_Persistent' ,'M+_PCNN_EUV', 'M+_PCNN_Blos', #'M+_PCNN_Both_Avg', 'M+_PCNN_Both_Max',\n",
    "             ]\n",
    "modelsTab =  [modelDictRev[m] for m in modelsTab]\n",
    "\n",
    "viz[viz['filter']=='all'].set_index('model').loc[modelsTab,col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AC - metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz[viz['filter']=='windowChanging'].set_index('model').loc[modelsTab,col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NC - metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz[viz['filter']=='windowConstant'].set_index('model').loc[modelsTab,col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box Plot (Test & CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['tss','hss', 'mcc','f1']\n",
    "\n",
    "modelOrder = {'C+_Persistent\\nValidation' : 0,\n",
    "              'C+_PCNN_Blos\\nValidation' : 1,\n",
    "              'C+_PCNN_Blos\\nOperational Test\\n(CV folds models)' : 2,\n",
    "              'C+_PCNN_EUV\\nValidation' : 3,\n",
    "              'C+_PCNN_EUV\\nOperational Test\\n(CV folds models)' : 4,\n",
    "              'M+_Persistent\\nValidation' : 0,\n",
    "              'M+_PCNN_Blos\\nValidation' : 1,\n",
    "              'M+_PCNN_Blos\\nOperational Test\\n(CV folds models)' : 2,\n",
    "              'M+_PCNN_EUV\\nValidation' : 3,\n",
    "              'M+_PCNN_EUV\\nOperational Test\\n(CV folds models)' : 4,\n",
    "              }\n",
    "modelsBoxPlot = list(set([modelDictRev[model.split('\\n')[0]] for model in modelOrder.keys()]))\n",
    "\n",
    "\n",
    "# Dataframe for test bp\n",
    "perfs = perfTest[perfTest['filter']=='all'].reset_index().copy()\n",
    "perfs = perfs[perfs['startingDate']==perfs['startingDate'].min()]\n",
    "dfBp = pd.DataFrame({col:[] for col in ['model', 'fold','performance', 'metric']})\n",
    "for i in range(len(perfs)):\n",
    "  for mtc in metrics:\n",
    "    fold = perfs.loc[i,'modelFdId']\n",
    "    model = perfs.loc[i,'model']\n",
    "    if fold not in ['']:#['fd000']:\n",
    "      perf = perfs.loc[i,mtc]\n",
    "      tmp = pd.DataFrame({'model' : model,\n",
    "                          'fold' : fold,\n",
    "                          'performance' : perf,\n",
    "                          'metric' : mtc\n",
    "                          },index = [len(dfBp)])\n",
    "      dfBp = pd.concat([dfBp,tmp],axis=0)\n",
    "\n",
    "dfBp = dfBp[dfBp['model'].isin(modelsBoxPlot)]\n",
    "\n",
    "# Dataframe for val bp\n",
    "dfBp_val = {'model':[],\n",
    "            'performance' : [],\n",
    "            'metric' : [],\n",
    "            'fold' : []\n",
    "            }\n",
    "for modelName in modelsBoxPlot:\n",
    "  foldsPaths = sorted(glob((FOLDER/f'training_folds/training_{modelName}*').as_posix()))\n",
    "  for kf,fdPath in enumerate(foldsPaths):\n",
    "    for i,mtc in enumerate(metrics):\n",
    "      mtc = f'val_{mtc}'\n",
    "      tmp = pd.read_csv(fdPath)\n",
    "      tp = tmp['val_TP']\n",
    "      tn = tmp['val_TN']\n",
    "      fp = tmp['val_FP']\n",
    "      fn = tmp['val_FN']\n",
    "      tmp['val_mcc'] = (tp*tn - fp*fn) / np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "      dfBp_val['model'].append(modelName)\n",
    "      # print(dfBp_val['model'])\n",
    "      #dfBp[mtc1].append(np.max(tmp[mtc1]))\n",
    "      #dfBp[mtc2].append(tmp[mtc2].loc[np.argmax(tmp[mtc1])])\n",
    "      if i==0:\n",
    "        epc = np.argmax(tmp[mtc])\n",
    "        dfBp_val['performance'].append(np.max(tmp[mtc]))\n",
    "        # dfBp_val['epoch'].append(epc)\n",
    "      else:\n",
    "        dfBp_val['performance'].append(tmp[mtc].loc[epc])\n",
    "        # dfBp_val['epoch'].append(epc)\n",
    "      dfBp_val['metric'].append(mtc[4:])\n",
    "      dfBp_val['fold'].append(kf)\n",
    "dfBp_val = pd.DataFrame(dfBp_val)\n",
    "\n",
    "# for modelName in modelDict.keys():\n",
    "#   dfBp_val[dfBp_val['model'] == modelName]['model'] = modelDict[modelName] + '\\nValidation'\n",
    "dfBp_val['model'] = dfBp_val['model'].apply(lambda x: modelDict[x] + '\\nValidation')\n",
    "dfBp_val['fold'] = dfBp_val['fold'].apply(lambda x: str(x))\n",
    "# dfBp_val\n",
    "\n",
    "# Merging Test and Val\n",
    "dfTest = dfBp.copy()\n",
    "dfTest = dfTest[~dfTest['model'].isin(['C+_mpf_Persistent_24', 'M+_mpf_Persistent_24'])]\n",
    "dfTest['model'] = dfTest['model'].apply(lambda x: modelDict[x] + '\\nOperational Test\\n(CV folds models)')\n",
    "cls = dfTest['model'].reset_index()['model'][0][0]\n",
    "\n",
    "dfAll = pd.concat([dfBp_val,dfTest],axis=0)\n",
    "dfAll['order'] = dfAll['model'].apply(lambda x: modelOrder[x])\n",
    "dfAll = dfAll.sort_values(by=['order'], ascending = True)\n",
    "\n",
    "dfAll = dfAll[dfAll['metric'].isin(metrics)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeModel = 'C+'\n",
    "metrics = ['tss','hss']\n",
    "palette= ['whitesmoke','cornflowerblue']\n",
    "\n",
    "dfTemp = dfAll.copy()\n",
    "dfTemp = dfAll[dfAll['model'].apply(lambda x: x.split('_')[0]==typeModel)]\n",
    "\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (13,9)\n",
    "fontsize = 16\n",
    "plt.rcParams['font.size'] = fontsize\n",
    "plt.rcParams['legend.fontsize'] = fontsize\n",
    "plt.rcParams['xtick.labelsize'] = fontsize\n",
    "plt.rcParams['ytick.labelsize'] = fontsize\n",
    "plt.rcParams['axes.labelsize'] = fontsize\n",
    "\n",
    "\n",
    "cls = dfTemp['model'].reset_index()['model'][0][0]\n",
    "\n",
    "color = 'silver' # 'lightblue' 'cornflowerblue'\n",
    "\n",
    "box_plot = sns.boxplot(x = 'model', y = 'performance', hue='metric',\n",
    "            data = dfTemp[dfTemp['fold']!='avg'].sort_values(by=['order'], ascending = True),\n",
    "            hue_order=metrics,\n",
    "            dodge=True,\n",
    "            linewidth=2.5,\n",
    "            # palette= sns.color_palette([color]) ,#\"Blues\",#\n",
    "            # color = 'cornflowerblue',\n",
    "            palette= palette,\n",
    "            showmeans = True,\n",
    "            meanprops={\"marker\":\"o\",\n",
    "                      \"markerfacecolor\":\"darkorange\",\n",
    "                      \"markeredgecolor\":\"darkorange\",\n",
    "                      \"markersize\":\"8\"}\n",
    ")\n",
    "\n",
    "for j,xtick in  enumerate(box_plot.get_xticks()):\n",
    "  for idx, mtc in enumerate(metrics):\n",
    "    # mtc = metrics[idx % len(metrics)]\n",
    "    modelList = [m for m in list(modelOrder.keys()) if m.split('_')[0]==typeModel]\n",
    "    tmp_all = dfTemp[(dfTemp['metric']==mtc) & (dfTemp['model']==modelList[j])]\n",
    "    tmp = tmp_all[tmp_all['fold']!='avg']\n",
    "    means = tmp.groupby(['model'])['performance'].mean()[0]#.sort_index(key=lambda x: x.map(modelsOrder))\n",
    "    maxs = tmp.groupby(['model'])['performance'].max()#.sort_index(key=lambda x: x.map(modelsOrder))\n",
    "    stds = tmp.groupby(['model'])['performance'].std()[0]#.sort_index(key=lambda x: x.map(modelsOrder))\n",
    "    vertical_offset = 0.0065 #means * 0.02 # offset from median for display\n",
    "    # vertical_offset = 0.0012\n",
    "    # vertical_offset = 0.01\n",
    "    x = 0.2\n",
    "    if idx == 0:\n",
    "      x = -x\n",
    "    box_plot.text(j+x,\n",
    "                  means + vertical_offset,\n",
    "                  f'{means:.3f}',\n",
    "                  horizontalalignment='center',\n",
    "                  size='x-small',\n",
    "                  color='black',\n",
    "                  #weight='semibold'\n",
    "                  )\n",
    "    box_plot.text(j+x,\n",
    "                  means - vertical_offset*1.6,\n",
    "                  f'(± {stds:.3f})',\n",
    "                  horizontalalignment='center',\n",
    "                  size='x-small',\n",
    "                  color='black',\n",
    "                  #weight='semibold'\n",
    "                  )\n",
    "    vertical_offset = 0.007\n",
    "    if j % 2 == 0 and j>0:\n",
    "      if idx == 0:\n",
    "        color = 'lightslategray'\n",
    "        # box_plot.text(j+x,\n",
    "        #           tmp_all[tmp_all['fold']=='avg']['performance'] - vertical_offset - 0.001,\n",
    "        #           f'        Ensemble Model',\n",
    "        #           horizontalalignment='center',\n",
    "        #           size='x-small',\n",
    "        #           color='black',\n",
    "        #           #weight='semibold'\n",
    "        #           )\n",
    "      else:\n",
    "        color = 'cornflowerblue'\n",
    "      box_plot.plot(j+x, tmp_all[tmp_all['fold']=='avg']['performance'], marker='*', markersize=20, color = color)\n",
    "      res = tmp_all[tmp_all['fold']=='avg']['performance'].values[0]\n",
    "      box_plot.text(j+x,\n",
    "                  tmp_all[tmp_all['fold']=='avg']['performance'] + vertical_offset - 0.0015,\n",
    "                  f'{res:.3f}',\n",
    "                  horizontalalignment='center',\n",
    "                  size='x-small',\n",
    "                  color='black',\n",
    "                  #weight='semibold'\n",
    "                  )\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(f'{cls}+ Forecasts Cross-Validation and Operational Test', fontsize=fontsize+2)\n",
    "\n",
    "# box_plot.set_ylim(bottom = 0.625, top = 0.755)\n",
    "# box_plot.set_ylim(bottom = 0.55)\n",
    "box_plot.set_xlabel('')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# plt.axhline(perfs[(perfs.model=='M+_mpf_Persistent') & (perfs.modelFdId=='avg')]['tss'].values, color = 'red', linestyle = ':')\n",
    "box_plot.axhline(perfs[(perfs.model==f'{cls}+_mpf_Persistent_24') & (perfs.modelFdId=='avg')][metrics[0]].values, color = color, linestyle = '--', label ='Persistent Operation Test')\n",
    "\n",
    "# labels = [metrics[0], \"persitant model\\non operational test\", \"M+_Persistent\\nOperational Test\\n(tss & hss)\"]\n",
    "labels = [metrics[0], metrics[1], \"persitant model\\non operational test\\n(tss & hss)\"]\n",
    "handles, _ = box_plot.get_legend_handles_labels()\n",
    "\n",
    "# Slice list to remove first handle\n",
    "\n",
    "for patch in box_plot.artists:\n",
    "  patch.set_facecolor('red')\n",
    "\n",
    "plt.legend(handles = handles, labels = labels, loc = 'lower left')\n",
    "# box_plot.axhline(perfs[(perfs.model=='M+_mpf_Persistent') & (perfs.modelFdId=='avg')]['tss'].values, color = 'red', linestyle = ':')\n",
    "\n",
    "# plt.title(f'{cls}+ models {metrics[0]} scores on Cross-Validation and Operational Test', fontsize=fontsize+2)\n",
    "\n",
    "plt.title(f'{cls}+ models scores on Cross-Validation and Operational Test', fontsize=fontsize+2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M+ -- TSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeModel = 'M+'\n",
    "metrics = ['tss']\n",
    "palette = ['whitesmoke']\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "dfTemp = dfAll.copy()\n",
    "dfTemp = dfAll[dfAll['model'].apply(lambda x: x.split('_')[0]==typeModel)]\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (13,9)\n",
    "fontsize = 16\n",
    "plt.rcParams['font.size'] = fontsize\n",
    "plt.rcParams['legend.fontsize'] = fontsize\n",
    "plt.rcParams['xtick.labelsize'] = fontsize\n",
    "plt.rcParams['ytick.labelsize'] = fontsize\n",
    "plt.rcParams['axes.labelsize'] = fontsize\n",
    "\n",
    "\n",
    "cls = dfTemp['model'].reset_index()['model'][0][0]\n",
    "\n",
    "dfTemp = dfTemp[dfTemp['metric'].isin(metrics)]\n",
    "\n",
    "color = 'silver' # 'lightblue' 'cornflowerblue'\n",
    "\n",
    "box_plot = sns.boxplot(x = 'model', y = 'performance', hue='metric',\n",
    "            data = dfTemp[dfTemp['fold']!='avg'].sort_values(by=['order'], ascending = True),\n",
    "            dodge=True,\n",
    "            linewidth=2.5,\n",
    "            palette= palette ,#\"Blues\",#\n",
    "            # color = 'cornflowerblue',\n",
    "            showmeans = True,\n",
    "            meanprops={\"marker\":\"o\",\n",
    "                      \"markerfacecolor\":\"darkorange\",\n",
    "                      \"markeredgecolor\":\"darkorange\",\n",
    "                      \"markersize\":\"8\"}\n",
    ")\n",
    "\n",
    "# for patch in box_plot.artists:\n",
    "#   patch.set_facecolor('cornflowerblue')\n",
    "\n",
    "\n",
    "for j,xtick in  enumerate(box_plot.get_xticks()):\n",
    "  for idx, mtc in enumerate(metrics):\n",
    "    # mtc = metrics[idx % len(metrics)]\n",
    "    modelList = [m for m in list(modelOrder.keys()) if m.split('_')[0]==typeModel]\n",
    "    tmp_all = dfTemp[(dfTemp['metric']==mtc) & (dfTemp['model']==modelList[j])]\n",
    "    tmp = tmp_all[tmp_all['fold']!='avg']\n",
    "    means = tmp.groupby(['model'])['performance'].mean()[0]#.sort_index(key=lambda x: x.map(modelsOrder))\n",
    "    maxs = tmp.groupby(['model'])['performance'].max()#.sort_index(key=lambda x: x.map(modelsOrder))\n",
    "    stds = tmp.groupby(['model'])['performance'].std()[0]#.sort_index(key=lambda x: x.map(modelsOrder))\n",
    "    vertical_offset = 0.0055 #means * 0.02 # offset from median for display\n",
    "    # vertical_offset = 0.0012\n",
    "    # vertical_offset = 0.01\n",
    "    x = 0\n",
    "    if idx == 0:\n",
    "      x = -x\n",
    "    box_plot.text(j+x,\n",
    "                  means + vertical_offset,\n",
    "                  f'{means:.3f}',\n",
    "                  horizontalalignment='center',\n",
    "                  size='x-small',\n",
    "                  color='black',\n",
    "                  #weight='semibold'\n",
    "                  )\n",
    "    box_plot.text(j+x,\n",
    "                  means - vertical_offset*1.6,\n",
    "                  f'(± {stds:.3f})',\n",
    "                  horizontalalignment='center',\n",
    "                  size='x-small',\n",
    "                  color='black',\n",
    "                  #weight='semibold'\n",
    "                  )\n",
    "    vertical_offset = 0.007\n",
    "    if j % 2 == 0 and j>0:\n",
    "      if idx == 0:\n",
    "        color = 'lightslategray'\n",
    "        # box_plot.text(j+x,\n",
    "        #           tmp_all[tmp_all['fold']=='avg']['performance'] - vertical_offset - 0.001,\n",
    "        #           f'        Ensemble Model',\n",
    "        #           horizontalalignment='center',\n",
    "        #           size='x-small',\n",
    "        #           color='black',\n",
    "        #           #weight='semibold'\n",
    "        #           )\n",
    "      else:\n",
    "        color = 'cornflowerblue'\n",
    "      box_plot.plot(j+x, tmp_all[tmp_all['fold']=='avg']['performance'], marker='*', markersize=20, color = color)\n",
    "      res = tmp_all[tmp_all['fold']=='avg']['performance'].values[0]\n",
    "      box_plot.text(j+x,\n",
    "                  tmp_all[tmp_all['fold']=='avg']['performance'] + vertical_offset - 0.0015,\n",
    "                  f'{res:.3f}',\n",
    "                  horizontalalignment='center',\n",
    "                  size='x-small',\n",
    "                  color='black',\n",
    "                  #weight='semibold'\n",
    "                  )\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(f'{cls}+ Forecasts Cross-Validation and Operational Test', fontsize=fontsize+2)\n",
    "\n",
    "# box_plot.set_ylim(bottom = 0.625, top = 0.755)\n",
    "# box_plot.set_ylim(bottom = 0.55)\n",
    "box_plot.set_xlabel('')\n",
    "box_plot.set_ylabel(metrics[0])\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# plt.axhline(perfs[(perfs.model=='M+_mpf_Persistent') & (perfs.modelFdId=='avg')]['tss'].values, color = 'red', linestyle = ':')\n",
    "box_plot.axhline(perfs[(perfs.model==f'{cls}+_mpf_Persistent_24') & (perfs.modelFdId=='avg')][metrics[0]].values, color = color, linestyle = '--', label ='Persistent Operation Test')\n",
    "\n",
    "# labels = [metrics[0], \"persitant model\\non operational test\", \"M+_Persistent\\nOperational Test\\n(tss & hss)\"]\n",
    "labels = [metrics[0], \"persitant model\\non operational test\"]\n",
    "handles, _ = box_plot.get_legend_handles_labels()\n",
    "\n",
    "# Slice list to remove first handle\n",
    "\n",
    "for patch in box_plot.artists:\n",
    "  patch.set_facecolor('red')\n",
    "\n",
    "plt.legend(handles = handles, labels = labels, loc = 'lower left')\n",
    "# box_plot.axhline(perfs[(perfs.model=='M+_mpf_Persistent') & (perfs.modelFdId=='avg')]['tss'].values, color = 'red', linestyle = ':')\n",
    "\n",
    "# plt.title(f'{cls}+ models {metrics[0]} scores on Cross-Validation and Operational Test', fontsize=fontsize+2)\n",
    "\n",
    "plt.title(f'{cls}+ models scores on Cross-Validation and Operational Test', fontsize=fontsize+2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M+ -- HSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeModel = 'M+'\n",
    "metrics = ['hss']\n",
    "palette = ['palette']\n",
    "color = 'cornflowerblue' # 'lightblue' 'cornflowerblue'\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "dfTemp = dfAll.copy()\n",
    "dfTemp = dfAll[dfAll['model'].apply(lambda x: x.split('_')[0]==typeModel)]\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (13,9)\n",
    "fontsize = 16\n",
    "plt.rcParams['font.size'] = fontsize\n",
    "plt.rcParams['legend.fontsize'] = fontsize\n",
    "plt.rcParams['xtick.labelsize'] = fontsize\n",
    "plt.rcParams['ytick.labelsize'] = fontsize\n",
    "plt.rcParams['axes.labelsize'] = fontsize\n",
    "\n",
    "\n",
    "cls = dfTemp['model'].reset_index()['model'][0][0]\n",
    "\n",
    "dfTemp = dfTemp[dfTemp['metric'].isin(metrics)]\n",
    "\n",
    "\n",
    "box_plot = sns.boxplot(x = 'model', y = 'performance', hue='metric',\n",
    "            data = dfTemp[dfTemp['fold']!='avg'].sort_values(by=['order'], ascending = True),\n",
    "            dodge=True,\n",
    "            linewidth=2.5,\n",
    "            palette= sns.color_palette([color]) ,#\"Blues\",#\n",
    "            # color = 'cornflowerblue',\n",
    "            showmeans = True,\n",
    "            meanprops={\"marker\":\"o\",\n",
    "                      \"markerfacecolor\":\"darkorange\",\n",
    "                      \"markeredgecolor\":\"darkorange\",\n",
    "                      \"markersize\":\"8\"}\n",
    ")\n",
    "\n",
    "# for patch in box_plot.artists:\n",
    "#   patch.set_facecolor('cornflowerblue')\n",
    "\n",
    "\n",
    "for j,xtick in  enumerate(box_plot.get_xticks()):\n",
    "  for idx, mtc in enumerate(metrics):\n",
    "    modelList = [m for m in list(modelOrder.keys()) if m.split('_')[0]==typeModel]\n",
    "    tmp_all = dfTemp[(dfTemp['metric']==mtc) & (dfTemp['model']==modelList[j])]\n",
    "    tmp = tmp_all[tmp_all['fold']!='avg']\n",
    "    means = tmp.groupby(['model'])['performance'].mean()[0]#.sort_index(key=lambda x: x.map(modelsOrder))\n",
    "    maxs = tmp.groupby(['model'])['performance'].max()#.sort_index(key=lambda x: x.map(modelsOrder))\n",
    "    stds = tmp.groupby(['model'])['performance'].std()[0]#.sort_index(key=lambda x: x.map(modelsOrder))\n",
    "    vertical_offset = 0.004 #means * 0.02 # offset from median for display\n",
    "    # vertical_offset = 0.0012\n",
    "    # vertical_offset = 0.01\n",
    "    x = 0\n",
    "    if idx == 0:\n",
    "      x = -x\n",
    "    box_plot.text(j+x,\n",
    "                  means + vertical_offset,\n",
    "                  f'{means:.3f}',\n",
    "                  horizontalalignment='center',\n",
    "                  size='x-small',\n",
    "                  color='black',\n",
    "                  #weight='semibold'\n",
    "                  )\n",
    "    box_plot.text(j+x,\n",
    "                  means - vertical_offset*1.9,\n",
    "                  f'(± {stds:.3f})',\n",
    "                  horizontalalignment='center',\n",
    "                  size='x-small',\n",
    "                  color='black',\n",
    "                  #weight='semibold'\n",
    "                  )\n",
    "    vertical_offset = 0.0112\n",
    "    if j % 2 == 0 and j>0:\n",
    "      if idx == 0:\n",
    "        color = 'cornflowerblue'\n",
    "        # box_plot.text(j+x,\n",
    "        #           tmp_all[tmp_all['fold']=='avg']['performance'] - vertical_offset - 0.001,\n",
    "        #           f'        Ensemble Model',\n",
    "        #           horizontalalignment='center',\n",
    "        #           size='x-small',\n",
    "        #           color='black',\n",
    "        #           #weight='semibold'\n",
    "        #           )\n",
    "      else:\n",
    "        color = 'cornflowerblue'\n",
    "      box_plot.plot(j+x, tmp_all[tmp_all['fold']=='avg']['performance'], marker='*', markersize=20, color = 'blue',markeredgecolor='white')\n",
    "      res = tmp_all[tmp_all['fold']=='avg']['performance'].values[0]\n",
    "      box_plot.text(j+x,\n",
    "                  tmp_all[tmp_all['fold']=='avg']['performance'] + vertical_offset - 0.0015,\n",
    "                  f'{res:.3f}',\n",
    "                  horizontalalignment='center',\n",
    "                  size='x-small',\n",
    "                  color='black',\n",
    "                  #weight='semibold'\n",
    "                  )\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(f'{cls}+ Forecasts Cross-Validation and Operational Test', fontsize=fontsize+2)\n",
    "\n",
    "# box_plot.set_ylim(bottom = 0.625, top = 0.755)\n",
    "# box_plot.set_ylim(bottom = 0.55)\n",
    "box_plot.set_xlabel('')\n",
    "\n",
    "box_plot.set_ylabel(metrics[0])\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# plt.axhline(perfs[(perfs.model=='M+_mpf_Persistent') & (perfs.modelFdId=='avg')]['tss'].values, color = 'red', linestyle = ':')\n",
    "box_plot.axhline(perfs[(perfs.model==f'{cls}+_mpf_Persistent_24') & (perfs.modelFdId=='avg')][metrics[0]].values, color = color, linestyle = '--', label ='Persistent Operation Test')\n",
    "\n",
    "# labels = [metrics[0], \"persitant model\\non operational test\", \"M+_Persistent\\nOperational Test\\n(tss & hss)\"]\n",
    "labels = [metrics[0], \"persitant model\\non operational test\"]\n",
    "handles, _ = box_plot.get_legend_handles_labels()\n",
    "\n",
    "# Slice list to remove first handle\n",
    "\n",
    "for patch in box_plot.artists:\n",
    "  patch.set_facecolor('red')\n",
    "\n",
    "plt.legend(handles = handles, labels = labels, loc = 'lower left')\n",
    "# box_plot.axhline(perfs[(perfs.model=='M+_mpf_Persistent') & (perfs.modelFdId=='avg')]['tss'].values, color = 'red', linestyle = ':')\n",
    "\n",
    "# plt.title(f'{cls}+ models {metrics[0]} scores on Cross-Validation and Operational Test', fontsize=fontsize+2)\n",
    "\n",
    "plt.title(f'{cls}+ models scores on Cross-Validation and Operational Test', fontsize=fontsize+2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AC - Box plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AC Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['tss','hss','mcc','f1']\n",
    "\n",
    "modelOrder = {\n",
    "              'C+_PCNN_Blos\\nOperational Test\\n(CV folds models)' : 0,\n",
    "              'C+_PCNN_EUV\\nOperational Test\\n(CV folds models)' : 1,\n",
    "              'M+_PCNN_Blos\\nOperational Test\\n(CV folds models)' : 2,\n",
    "              'M+_PCNN_EUV\\nOperational Test\\n(CV folds models)' : 3,\n",
    "              }\n",
    "modelsBoxPlot = list(set([modelDictRev[model.split('\\n')[0]] for model in modelOrder.keys()]))\n",
    "\n",
    "\n",
    "# Dataframe for test bp\n",
    "perfs = perfTest[perfTest['filter']=='windowChanging'].reset_index().copy()\n",
    "perfs = perfs[perfs['startingDate']==perfs['startingDate'].min()]\n",
    "dfBp = pd.DataFrame({col:[] for col in ['model', 'fold','performance', 'metric']})\n",
    "for i in range(len(perfs)):\n",
    "  for mtc in metrics:\n",
    "    fold = perfs.loc[i,'modelFdId']\n",
    "    model = perfs.loc[i,'model']\n",
    "    if fold not in ['']:#['fd000']:\n",
    "      perf = perfs.loc[i,mtc]\n",
    "      tmp = pd.DataFrame({'model' : model,\n",
    "                          'fold' : fold,\n",
    "                          'performance' : perf,\n",
    "                          'metric' : mtc\n",
    "                          },index = [len(dfBp)])\n",
    "      dfBp = pd.concat([dfBp,tmp],axis=0)\n",
    "\n",
    "dfBp = dfBp[dfBp['model'].isin(modelsBoxPlot)]\n",
    "\n",
    "# # Dataframe for val bp\n",
    "# dfBp_val = {'model':[],\n",
    "#             'performance' : [],\n",
    "#             'metric' : [],\n",
    "#             'fold' : []\n",
    "#             }\n",
    "# for modelName in modelsBoxPlot:\n",
    "#   foldsPaths = sorted(glob((FOLDER/f'training_folds/training_{modelName}*').as_posix()))\n",
    "#   for kf,fdPath in enumerate(foldsPaths):\n",
    "#     for i,mtc in enumerate(metrics):\n",
    "#       mtc = f'val_{mtc}'\n",
    "#       tmp = pd.read_csv(fdPath)\n",
    "#       tp = tmp['val_TP']\n",
    "#       tn = tmp['val_TN']\n",
    "#       fp = tmp['val_FP']\n",
    "#       fn = tmp['val_FN']\n",
    "#       tmp['val_mcc'] = (tp*tn - fp*fn) / np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "#       dfBp_val['model'].append(modelName)\n",
    "#       # print(dfBp_val['model'])\n",
    "#       #dfBp[mtc1].append(np.max(tmp[mtc1]))\n",
    "#       #dfBp[mtc2].append(tmp[mtc2].loc[np.argmax(tmp[mtc1])])\n",
    "#       if i==0:\n",
    "#         epc = np.argmax(tmp[mtc])\n",
    "#         dfBp_val['performance'].append(np.max(tmp[mtc]))\n",
    "#         # dfBp_val['epoch'].append(epc)\n",
    "#       else:\n",
    "#         dfBp_val['performance'].append(tmp[mtc].loc[epc])\n",
    "#         # dfBp_val['epoch'].append(epc)\n",
    "#       dfBp_val['metric'].append(mtc[4:])\n",
    "#       dfBp_val['fold'].append(kf)\n",
    "# dfBp_val = pd.DataFrame(dfBp_val)\n",
    "\n",
    "# # for modelName in modelDict.keys():\n",
    "# #   dfBp_val[dfBp_val['model'] == modelName]['model'] = modelDict[modelName] + '\\nValidation'\n",
    "# dfBp_val['model'] = dfBp_val['model'].apply(lambda x: modelDict[x] + '\\nValidation')\n",
    "# dfBp_val['fold'] = dfBp_val['fold'].apply(lambda x: str(x))\n",
    "# # dfBp_val\n",
    "\n",
    "# Merging Test and Val\n",
    "dfTest = dfBp.copy()\n",
    "dfTest = dfTest[~dfTest['model'].isin(['C+_mpf_Persistent_24', 'M+_mpf_Persistent_24'])]\n",
    "dfTest['model'] = dfTest['model'].apply(lambda x: modelDict[x] + '\\nOperational Test\\n(CV folds models)')\n",
    "cls = dfTest['model'].reset_index()['model'][0][0]\n",
    "\n",
    "dfAll =   dfTest# pd.concat([dfBp_val,dfTest],axis=0)\n",
    "dfAll['order'] = dfAll['model'].apply(lambda x: modelOrder[x])\n",
    "dfAll = dfAll.sort_values(by=['order'], ascending = True)\n",
    "\n",
    "dfAll = dfAll[dfAll['metric'].isin(metrics)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AC plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# typeModel = 'C+'\n",
    "metrics = ['tss','hss']\n",
    "palette= ['whitesmoke','cornflowerblue']\n",
    "\n",
    "dfTemp = dfAll.copy()\n",
    "# dfTemp = dfAll[dfAll['model'].apply(lambda x: x.split('_')[0]==typeModel)]\n",
    "\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (13,9)\n",
    "fontsize = 16\n",
    "plt.rcParams['font.size'] = fontsize\n",
    "plt.rcParams['legend.fontsize'] = fontsize\n",
    "plt.rcParams['xtick.labelsize'] = fontsize\n",
    "plt.rcParams['ytick.labelsize'] = fontsize\n",
    "plt.rcParams['axes.labelsize'] = fontsize\n",
    "\n",
    "\n",
    "cls = dfTemp['model'].reset_index()['model'][0][0]\n",
    "\n",
    "color = 'silver' # 'lightblue' 'cornflowerblue'\n",
    "\n",
    "box_plot = sns.boxplot(x = 'model', y = 'performance', hue='metric',\n",
    "            data = dfTemp[dfTemp['fold']!='avg'].sort_values(by=['order'], ascending = True),\n",
    "            hue_order=metrics,\n",
    "            dodge=True,\n",
    "            linewidth=2.5,\n",
    "            # palette= sns.color_palette([color]) ,#\"Blues\",#\n",
    "            # color = 'cornflowerblue',\n",
    "            palette= palette,\n",
    "            showmeans = True,\n",
    "            meanprops={\"marker\":\"o\",\n",
    "                      \"markerfacecolor\":\"darkorange\",\n",
    "                      \"markeredgecolor\":\"darkorange\",\n",
    "                      \"markersize\":\"8\"}\n",
    ")\n",
    "\n",
    "for j,xtick in  enumerate(box_plot.get_xticks()):\n",
    "  for idx, mtc in enumerate(metrics):\n",
    "    # mtc = metrics[idx % len(metrics)]\n",
    "    modelList = [m for m in list(modelOrder.keys())]# if m.split('_')[0]==typeModel]\n",
    "    tmp_all = dfTemp[(dfTemp['metric']==mtc) & (dfTemp['model']==modelList[j])]\n",
    "    tmp = tmp_all[tmp_all['fold']!='avg']\n",
    "    means = tmp.groupby(['model'])['performance'].mean()[0]#.sort_index(key=lambda x: x.map(modelsOrder))\n",
    "    maxs = tmp.groupby(['model'])['performance'].max()#.sort_index(key=lambda x: x.map(modelsOrder))\n",
    "    stds = tmp.groupby(['model'])['performance'].std()[0]#.sort_index(key=lambda x: x.map(modelsOrder))\n",
    "    vertical_offset = 0.0065 #means * 0.02 # offset from median for display\n",
    "    # vertical_offset = 0.0012\n",
    "    # vertical_offset = 0.01\n",
    "    x = 0.2\n",
    "    if idx == 0:\n",
    "      x = -x\n",
    "    # box_plot.text(j+x,\n",
    "    #               means + vertical_offset,\n",
    "    #               f'{means:.3f}',\n",
    "    #               horizontalalignment='center',\n",
    "    #               size='x-small',\n",
    "    #               color='black',\n",
    "    #               #weight='semibold'\n",
    "    #               )\n",
    "    # box_plot.text(j+x,\n",
    "    #               means - vertical_offset*1.6,\n",
    "    #               f'(± {stds:.3f})',\n",
    "    #               horizontalalignment='center',\n",
    "    #               size='x-small',\n",
    "    #               color='black',\n",
    "    #               #weight='semibold'\n",
    "    #               )\n",
    "    vertical_offset = 0.007\n",
    "    # if j % 2 == 0 and j>0:\n",
    "    if idx == 0:\n",
    "      color = 'lightslategray'\n",
    "      # box_plot.text(j+x,\n",
    "      #           tmp_all[tmp_all['fold']=='avg']['performance'] - vertical_offset - 0.001,\n",
    "      #           f'        Ensemble Model',\n",
    "      #           horizontalalignment='center',\n",
    "      #           size='x-small',\n",
    "      #           color='black',\n",
    "      #           #weight='semibold'\n",
    "      #           )\n",
    "    else:\n",
    "      color = 'blue'\n",
    "      \n",
    "    box_plot.plot(j+x, tmp_all[tmp_all['fold']=='avg']['performance'], marker='*', markersize=20, color = color)\n",
    "    \n",
    "    res = tmp_all[tmp_all['fold']=='avg']['performance'].values[0]\n",
    "    box_plot.text(j+x,\n",
    "                tmp_all[tmp_all['fold']=='avg']['performance'] + vertical_offset - 0.0015,\n",
    "                f'{res:.3f}',\n",
    "                horizontalalignment='center',\n",
    "                size='x-small',\n",
    "                color='black',\n",
    "                #weight='semibold'\n",
    "                )\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(f'{cls}+ Forecasts Cross-Validation and Operational Test', fontsize=fontsize+2)\n",
    "\n",
    "# box_plot.set_ylim(bottom = 0.625, top = 0.755)\n",
    "# box_plot.set_ylim(bottom = 0.55)\n",
    "box_plot.set_xlabel('')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# plt.axhline(perfs[(perfs.model=='M+_mpf_Persistent') & (perfs.modelFdId=='avg')]['tss'].values, color = 'red', linestyle = ':')\n",
    "box_plot.axhline(0.0, color = 'cornflowerblue', linestyle = '--', label ='skill-threshold')\n",
    "\n",
    "# labels = [metrics[0], \"persitant model\\non operational test\", \"M+_Persistent\\nOperational Test\\n(tss & hss)\"]\n",
    "labels = [metrics[0], metrics[1], \"skill-threshold\"]\n",
    "handles, _ = box_plot.get_legend_handles_labels()\n",
    "\n",
    "# Slice list to remove first handle\n",
    "\n",
    "for patch in box_plot.artists:\n",
    "  patch.set_facecolor('red')\n",
    "\n",
    "plt.legend(handles = handles, labels = labels, loc = 'upper right')\n",
    "# box_plot.axhline(perfs[(perfs.model=='M+_mpf_Persistent') & (perfs.modelFdId=='avg')]['tss'].values, color = 'red', linestyle = ':')\n",
    "\n",
    "# plt.title(f'{cls}+ models {metrics[0]} scores on Cross-Validation and Operational Test', fontsize=fontsize+2)\n",
    "\n",
    "plt.title(f'Models Operational Performances on Time Windows With Activity Change', fontsize=fontsize+2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pathes Performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patches' Labels Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sundl.utils.flare.windows import windowHistoryFromFlList_ByPatchSector_EXACT\n",
    "\n",
    "CORRECTED_SECTOR = True\n",
    "window_h         = 24\n",
    "timeRes_h        = 2\n",
    "num_patches      = 8\n",
    "path_label_ptchs = F_PATH_LABEL_PATCHES(num_patches, timeRes_h, window_h)\n",
    "\n",
    "# Take a few minutes (~5) if not already saved\n",
    "if path_label_ptchs.exists():\n",
    "  with open(path_label_ptchs, 'rb') as f1:\n",
    "    fl_historys = pickle.load(f1)\n",
    "else:\n",
    "  # Loading flare catalog with position\n",
    "  nan_val = 9999.0\n",
    "  flCatalog_positions = read_Dataframe_With_Dates(PATH_FLCATALOG_WITH_POS, ['timestamp','tstart'])\n",
    "  with open(PATH_MISSING_POS_DATES, 'rb') as f1:\n",
    "    missing_positions_events = pickle.load(f1)\n",
    "  print('MISSING DATES : ',len(missing_positions_events))\n",
    "  remove_date = flCatalog_positions[(flCatalog_positions.x == nan_val) | (flCatalog_positions.y == nan_val)]\n",
    "  # missing_positions_events = missing_positions_events.append(remove_date.reset_index()['timestamp']).reset_index(drop=True)\n",
    "  missing_positions_events = pd.concat([missing_positions_events,remove_date.reset_index()['timestamp']])\n",
    "  print('after nan rmvl: ',len(missing_positions_events))\n",
    "  # Computing sector-windows-history/features\n",
    "  fl_historys = windowHistoryFromFlList_ByPatchSector_EXACT(\n",
    "      flCatalog_positions,\n",
    "      missing_positions_events,\n",
    "      window_h = window_h, \n",
    "      timeRes_h = timeRes_h,\n",
    "      minDate = datetime.datetime(2020,1,1), \n",
    "      maxDate = None, \n",
    "      num_patches = num_patches)\n",
    "  with open(path_label_ptchs, 'wb') as f1:\n",
    "    pickle.dump(fl_historys, f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Patches Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sundl.utils.flare.thresholds import mpfTresh, totehTresh\n",
    "\n",
    "window_h   = 24\n",
    "labelCol   = 'mpf'\n",
    "\n",
    "\n",
    "modelsNames = [modelDictRev['C+_PCNN_EUV'],\n",
    "               modelDictRev['C+_PCNN_Blos'],\n",
    "               modelDictRev['M+_PCNN_EUV'],\n",
    "               modelDictRev['M+_PCNN_Blos'],\n",
    "               'C+_PCNN_Both_Max',\n",
    "               'M+_PCNN_Both_Max',\n",
    "               'C+_PCNN_Both_Avg',\n",
    "               'M+_PCNN_Both_Avg'\n",
    "               ]\n",
    "\n",
    "\n",
    "# ensModIsMax = True\n",
    "ensembles = {'C+_PCNN_Both_Max'  : [modelDictRev['C+_PCNN_EUV'], modelDictRev['C+_PCNN_Blos']],\n",
    "             'M+_PCNN_Both_Max'  : [modelDictRev['M+_PCNN_EUV'], modelDictRev['M+_PCNN_Blos']],\n",
    "             'C+_PCNN_Both_Avg'  : [modelDictRev['C+_PCNN_EUV'], modelDictRev['C+_PCNN_Blos']],\n",
    "             'M+_PCNN_Both_Avg'  : [modelDictRev['M+_PCNN_EUV'], modelDictRev['M+_PCNN_Blos']]\n",
    "            #  'C+_PCNN_Histo' : [modelDictRev[c+_PCNN_EUV'], modelDictRev['C+_PCNN_Blos'] , modelDictRev['C+_Persistent']],\n",
    "            #  'M+_PCNN_Histo' : [modelDictRev['M+_PCNN_EUV'], modelDictRev['M+_PCNN_Blos'] , modelDictRev['M+_Persistent']]\n",
    "             }\n",
    "\n",
    "ensembles = {}\n",
    "modelsNames = list(modelDict.keys())\n",
    "\n",
    "ptPredictions = {}\n",
    "\n",
    "if labelCol == 'mpf':\n",
    "  classTresholds = mpfTresh\n",
    "elif labelCol == 'toteh':\n",
    "  classTresholds = totehTresh[h]\n",
    "\n",
    "for modelName in modelsNames:\n",
    "  # pathPredPt =  pathPreds/f'{modelName}_pt.csv'\n",
    "  pathPredPt_withLabels = F_PATH_PREDS_MODEL(F_PATH_PREDS(FOLDER), modelName, 'pt', True)\n",
    "  if pathPredPt_withLabels.exists():\n",
    "    ptPredictions[modelName] = read_Dataframe_With_Dates(pathPredPt_withLabels)\n",
    "  else:\n",
    "    pathPredPt = F_PATH_PREDS_MODEL(F_PATH_PREDS(FOLDER), modelName, 'pt', False)\n",
    "    if modelName.split('_')[2]!='Persistent' and modelName.split('_')[0] in ['C+','M+']: # pathPredPt.exists() and # -->  pathPredPt must exists after notebook 3\n",
    "      ptPredictions[modelName] = read_Dataframe_With_Dates(pathPredPt)\n",
    "      # ptPredictions[modelName]['timestamp'] = ptPredictions[modelName]['timestamp'].apply(lambda x: datetime.datetime.strptime(x,'%Y-%m-%d %H:%M:%S')) # '%Y/%m/%d/H%H00/\n",
    "      # ptPredictions[modelName] = ptPredictions[modelName].set_index('timestamp',drop = True)\n",
    "      if 'label' in ptPredictions[modelName].columns:\n",
    "        ptPredictions[modelName] = ptPredictions[modelName].drop('label',axis=1)\n",
    "\n",
    "      ptcPredCols = [col for col in ptPredictions[modelName].columns if len(col)==len('pred_pt0')]\n",
    "      num_ptc = len(ptcPredCols)\n",
    "      # fl_historys = windowHistoryFromFlList_ByPatchSector(window_h = window_h, timeRes_h = 2, minDate = datetime.datetime(2020,1,1), maxDate = maxDate, num_patches = num_ptc)\n",
    "\n",
    "      for ptcId in range(num_ptc):\n",
    "        histo = fl_historys[ptcId].copy()\n",
    "        histo.index = histo.index + pd.DateOffset(hours= -window_h) # shifting history to window labels\n",
    "        ptPredictions[modelName] = pd.concat([ptPredictions[modelName],\n",
    "                                              histo[[labelCol]].rename(columns={labelCol:f'{labelCol}_pt{ptcId}'})\n",
    "                                              ], axis=1, join=\"inner\")\n",
    "        cls = modelName[0]\n",
    "        # @@@@@@@@@@@@ T\n",
    "        ptPredictions[modelName][f'label_pt{ptcId}'] = ptPredictions[modelName][f'{labelCol}_pt{ptcId}'].apply(lambda x: x>=classTresholds[cls][0])\n",
    "\n",
    "        ptPredictions[modelName][f'histo_pt{ptcId}'] = ptPredictions[modelName][f'label_pt{ptcId}'].rolling(window = f'{window_h}H',\n",
    "                                          closed = 'left', # min_periods = int(input_lag)\n",
    "                                          ).apply(\n",
    "                                            lambda x: x[0])\n",
    "        ptPredictions[modelName][f'change_pt{ptcId}'] = ptPredictions[modelName][f'histo_pt{ptcId}'] != ptPredictions[modelName][f'label_pt{ptcId}']\n",
    "        ptPredictions[modelName][f't2f_pt{ptcId}'] = histo['t2mpf_h']\n",
    "        ptPredictions[modelName][f'x_pt{ptcId}'] = histo['x']\n",
    "        ptPredictions[modelName][f'y_pt{ptcId}'] = histo['y']\n",
    "      pathPredPt_withLabels = F_PATH_PREDS_MODEL(F_PATH_PREDS(FOLDER), modelName, 'pt', True)\n",
    "      ptPredictions[modelName].to_csv(pathPredPt_withLabels)\n",
    "    \n",
    "# Creating persistent predictions at patch level\n",
    "for idx,modelName in enumerate([f'C+_{labelCol}_Persistent_{window_h}',f'M+_{labelCol}_Persistent_{window_h}']):\n",
    "  pathPredPt_withLabels = F_PATH_PREDS_MODEL(F_PATH_PREDS(FOLDER), modelName, 'pt', True)\n",
    "  if pathPredPt_withLabels.exists():\n",
    "    ptPredictions[modelName] = read_Dataframe_With_Dates(pathPredPt_withLabels)\n",
    "  else:\n",
    "    cls = modelName[:2]\n",
    "    tmp = ptPredictions[modelDictRev[f'{cls}_PCNN_EUV']].copy()\n",
    "    ptcPredCols = [col for col in tmp.columns if len(col)==len('pred_pt0')]\n",
    "    num_ptc = len(ptcPredCols)\n",
    "    ptPredictions[modelName] = tmp[[col for col in tmp.columns if col[:3]!='pre']]\n",
    "    # ptPredictions[modelName] = ptPredictions[modelName][[col for col in ptPredictions[modelName].columns if col[:3]!='lab']]\n",
    "    for ptcId in range(num_ptc):\n",
    "      ptPredictions[modelName][f'pred_pt{ptcId}'] = ptPredictions[modelName][f'histo_pt{ptcId}']\n",
    "      # ptPredictions[modelName][f'label_pt{ptcId}'] = ptPredictions[modelName][f'histo_pt{ptcId}']\n",
    "  # ptPredictions[list(ptPredictions.keys())[0]]\n",
    "    pathPredPt_withLabels = F_PATH_PREDS_MODEL(F_PATH_PREDS(FOLDER), modelName, 'pt', True)\n",
    "    ptPredictions[modelName].to_csv(pathPredPt_withLabels)\n",
    "\n",
    "\n",
    "\n",
    "# modelsNames = modelsNames + list(ensembles.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Peformances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilsTest import patchesPerformance\n",
    "\n",
    "startingDates = [datetime.datetime(2020,1,28)]\n",
    "filterNames   = ['all','windowChanging', 'windowConstant']\n",
    "includeFolds  = True\n",
    "\n",
    "perfTestPtTot, perfTestByPatch = patchesPerformance(\n",
    "    ptPredictions, \n",
    "    startingDates, \n",
    "    filterNames, \n",
    "    includeFolds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = 'all' # @['all', 'limb', 'center']\n",
    "\n",
    "viz = perfTestPtTot.copy()[(perfTestPtTot.modelFdId == 'avg') & (perfTestPtTot.group == group)]\n",
    "viz = viz[viz['startingDate']==viz['startingDate'].min()]\n",
    "\n",
    "# col = ['model', 'filter','tss', 'hss', 'f1', # 'modelFdId', 'group', 'thd'\n",
    "#        'recall', 'far', 'mcc', 'acc_w', 'fssp', 'fssr', 'bal_pos', 'switch_rate'\n",
    "# ]\n",
    "\n",
    "\n",
    "col = ['filter','tss', 'hss', 'mcc', 'f1',  'recall', 'far', 'bal_pos', 'switch_rate', 'fssp', 'fssr' ,'acc_w']\n",
    "\n",
    "# viz[viz['filter']=='all'].sort_values(['tss'], ascending = False)[col]\n",
    "\n",
    "modelsTab = ['C+_Persistent' ,'C+_PCNN_EUV', 'C+_PCNN_Blos', #'C+_PCNN_Both_Avg', 'C+_PCNN_Both_Max',\n",
    "             'M+_Persistent' ,'M+_PCNN_EUV', 'M+_PCNN_Blos', #'M+_PCNN_Both_Avg', 'M+_PCNN_Both_Max',\n",
    "             ]\n",
    "modelsTab =  [modelDictRev[m] for m in modelsTab]\n",
    "\n",
    "viz[viz['filter']=='all'].set_index('model').loc[modelsTab,col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AC - metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz[viz['filter']=='windowChanging'].set_index('model').loc[modelsTab,col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NC - meetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz[viz['filter']=='windowConstant'].set_index('model').loc[modelsTab,col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
