{"cells":[{"cell_type":"markdown","metadata":{"id":"mGMU4i5QWEfP"},"source":["# Test Predictions\n","\n","Notebook to compute and store predictions on the operational test set.\n","\n","Full-disk and patches/sector predictions are stored in separated files"]},{"cell_type":"markdown","metadata":{"id":"ygxqPEu8WEfR"},"source":["# Config"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2LYB2UhoWEfR"},"outputs":[],"source":["# !pip install tensorflow==2.15.0"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28947,"status":"ok","timestamp":1713538375935,"user":{"displayName":"gregoire francisco","userId":"13749045815358519395"},"user_tz":-120},"id":"u79fPhDzWEfS","outputId":"9aa5e48b-060f-467c-e34a-94ce73a9e81f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'sundl'...\n","remote: Enumerating objects: 973, done.\u001b[K\n","remote: Counting objects: 100% (88/88), done.\u001b[K\n","remote: Compressing objects: 100% (63/63), done.\u001b[K\n","remote: Total 973 (delta 56), reused 49 (delta 25), pack-reused 885\u001b[K\n","Receiving objects: 100% (973/973), 7.14 MiB | 14.48 MiB/s, done.\n","Resolving deltas: 100% (483/483), done.\n","Cloning into 'flare_limits_pcnn'...\n","remote: Enumerating objects: 403, done.\u001b[K\n","remote: Counting objects: 100% (403/403), done.\u001b[K\n","remote: Compressing objects: 100% (329/329), done.\u001b[K\n","remote: Total 403 (delta 83), reused 370 (delta 54), pack-reused 0\u001b[K\n","Receiving objects: 100% (403/403), 6.87 MiB | 13.47 MiB/s, done.\n","Resolving deltas: 100% (83/83), done.\n","Mounted at /content/drive\n","Collecting dill\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: dill\n","Successfully installed dill-0.3.8\n"]}],"source":["COLAB = True\n","\n","if COLAB :\n","  configSetup = {\n","      'COLAB'           : 'True',\n","      'PATH_ROOT_DRIVE' : '/content/drive/MyDrive/Projects/Forecast',\n","      'PATH_ROOT_LOCAL' : '/content/session',\n","      'PATH_SUNDL'      : '/content/sundl',\n","      'PATH_PROJECT'    : '/content/flare_limits_pcnn'\n","  }\n","  !git clone https://github.com/gfrancisco20/sundl.git\n","  !git clone https://github.com/gfrancisco20/flare_limits_pcnn.git\n","  import sys\n","  import re\n","  sys.path.append(configSetup['PATH_SUNDL'])\n","  sys.path.append(configSetup['PATH_PROJECT'])\n","  configFile = f'{configSetup[\"PATH_PROJECT\"]}/config.py'\n","  with open(configFile, 'r') as file:\n","    content = file.read()\n","  for constant in configSetup.keys():\n","    content = re.sub(re.compile(f'{constant} = .*'), f'{constant} = \\'{configSetup[constant]}\\'', content)\n","  with open(configFile, 'w') as file:\n","    file.write(content)\n","\n","from config import *\n","if COLAB:\n","  from sundl.utils.colab import mountDrive\n","  # mouting drive content in session on colab\n","  mountDrive()\n","!pip install dill\n","\n","# you must request the models  files  or recompute  them with folder 1  to run this  notebook"]},{"cell_type":"markdown","metadata":{"id":"obcLexqNWEfS"},"source":["# Setup"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1713538375935,"user":{"displayName":"gregoire francisco","userId":"13749045815358519395"},"user_tz":-120},"id":"VXGso7JjWEfT"},"outputs":[],"source":["FOLDER = PATH_RES/'Classification_PCNN_224x448x3xCV05_2024_03_28__0'# 'Results_Paper_PCNN' #\n","\n","# Seleted Models from the CV resullts\n","modelDict = {\n","  'C+_mpf_Persistent_24'                                     : 'C+_Persistent',\n","  'C+_mpf_jpg_PTx8_RtdXall_EquiC_AW1e5D1e4_blos_24'          : 'C+_PCNN_Blos', #\n","  'C+_mpf_jpg_PTx8_RtdXall_EquiC_AW1e5D1e4_0193x0211x0094_24': 'C+_PCNN_EUV',\n","  'M+_mpf_Persistent_24'                                     : 'M+_Persistent',\n","  'M+_mpf_jpg_PTx8_RtdXall_LowC2_AW1e5D1e4_0193x0211x0094_24': 'M+_PCNN_Blos',\n","  'M+_mpf_jpg_PTx8_RtdXall_LowC2_AW1e5D1e4_blos_24'          : 'M+_PCNN_EUV',\n","}\n","modelDictRev = {modelDict[oldName] : oldName for oldName in modelDict.keys()}\n","\n","ensembles = {'C+_PCNN_Both_Max'  : ['C+_PCNN_Blos','C+_PCNN_EUV'],\n","             'M+_PCNN_Both_Max'  : ['M+_PCNN_Blos','M+_PCNN_EUV'],\n","             'C+_PCNN_Both_Avg'  : ['C+_PCNN_Blos','C+_PCNN_EUV'],\n","             'M+_PCNN_Both_Avg'  : ['M+_PCNN_Blos','M+_PCNN_EUV']\n","            #  'C+_PCNN_Histo' : ['C+_PCNN_Blos','C+_PCNN_EUV','C+_Persistent'],\n","            #  'M+_PCNN_Histo' : ['M+_PCNN_Blos','M+_PCNN_EUV', 'M+_Persistent']\n","             }"]},{"cell_type":"markdown","metadata":{"id":"6n5TBMY3WEfT"},"source":["# Predictions"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":84989,"status":"ok","timestamp":1713538460920,"user":{"displayName":"gregoire francisco","userId":"13749045815358519395"},"user_tz":-120},"id":"-fu66hLkWWI5","outputId":"94d93276-1b2e-4c4a-f0ba-2589ddbb5d7a"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","images -- jpg/eq_blos_448.zip transfered in : 0 m 22.68 s\n","    jpg/eq_blos_448.zip unzipped in : 0 m 16.28 s\n","\n","images -- jpg/eq_0193x0211x0094_448.zip transfered in : 28558973 m 54.35 s\n","    jpg/eq_0193x0211x0094_448.zip unzipped in : 0 m 9.91 s\n","CPU times: user 19 s, sys: 9.87 s, total: 28.9 s\n","Wall time: 1min 24s\n"]}],"source":["%%time\n","from sundl.utils.colab import mountDrive, ressourcesSetAndCheck, drive2local\n","############################\n","# SETUP\n","############################\n","\n","# overwriting CLEAN_LOCAL :\n","CLEAN_LOCAL = False\n","\n","if CLEAN_LOCAL:\n","  shutil.rmtree(PATH_ROOT_LOCAL)\n","  os.makedirs(PATH_ROOT_LOCAL)\n","\n","# checking gpu and ram ressources\n","# ressourcesSetAndCheck(MIXED_PREC)\n","\n","############################\n","# DATA IMPORT\n","############################\n","\n","FILES2TRANSFER = {'images' : (PATH_ROOT_DRIVE_DS/'Images',        # source\n","                              PATH_IMAGES,                        # dest\n","                              ['jpg/eq_blos_448','jpg/eq_0193x0211x0094_448']#, ''] # files\n","                              )\n","                  }\n","\n","drive2local(FILES2TRANSFER)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4426933,"status":"ok","timestamp":1713548001292,"user":{"displayName":"gregoire francisco","userId":"13749045815358519395"},"user_tz":-120},"id":"5ZfybcvAWEfV","outputId":"bd5052ef-4a36-4bce-ac98-8addc2260978"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","MODEL :  C+_mpf_Persistent_24\n","FOLDS WITH MODELS:  ['fd000', 'fd001', 'fd002', 'fd003', 'fd004']\n","\n","\n","MODEL :  C+_mpf_jpg_PTx8_RtdXall_EquiC_AW1e5D1e4_blos_24\n","FOLDS WITH MODELS:  ['fd000', 'fd001', 'fd002', 'fd003', 'fd004']\n","WARNING : 12 NaN (droped) for label at ts 24\n","------------------------------\n","labels.shape (13317, 1)\n","------------------------------\n","img_size (224, 448, 3)\n","im.shape (224, 448)\n","209/209 [==============================] - 78s 324ms/step\n","209/209 [==============================] - 72s 322ms/step\n","209/209 [==============================] - 72s 324ms/step\n","209/209 [==============================] - 72s 323ms/step\n","209/209 [==============================] - 72s 324ms/step\n","209/209 [==============================] - 72s 323ms/step\n","209/209 [==============================] - 72s 324ms/step\n","209/209 [==============================] - 72s 323ms/step\n","209/209 [==============================] - 72s 322ms/step\n","209/209 [==============================] - 73s 323ms/step\n","\n","\n","MODEL :  C+_mpf_jpg_PTx8_RtdXall_EquiC_AW1e5D1e4_0193x0211x0094_24\n","FOLDS WITH MODELS:  ['fd000', 'fd001', 'fd002', 'fd003', 'fd004']\n","WARNING : 12 NaN (droped) for label at ts 24\n","------------------------------\n","labels.shape (13953, 1)\n","------------------------------\n","img_size (224, 448, 3)\n","im.shape (224, 448, 3)\n","219/219 [==============================] - 77s 325ms/step\n","219/219 [==============================] - 75s 323ms/step\n","219/219 [==============================] - 76s 324ms/step\n","219/219 [==============================] - 76s 322ms/step\n","219/219 [==============================] - 76s 323ms/step\n","219/219 [==============================] - 76s 323ms/step\n","219/219 [==============================] - 76s 324ms/step\n","219/219 [==============================] - 76s 325ms/step\n","219/219 [==============================] - 76s 324ms/step\n","219/219 [==============================] - 76s 322ms/step\n","\n","\n","MODEL :  M+_mpf_Persistent_24\n","FOLDS WITH MODELS:  ['fd000', 'fd001', 'fd002', 'fd003', 'fd004']\n","\n","\n","MODEL :  M+_mpf_jpg_PTx8_RtdXall_LowC2_AW1e5D1e4_0193x0211x0094_24\n","FOLDS WITH MODELS:  ['fd000', 'fd001', 'fd002', 'fd003', 'fd004']\n","WARNING : 12 NaN (droped) for label at ts 24\n","------------------------------\n","labels.shape (13953, 1)\n","------------------------------\n","img_size (224, 448, 3)\n","im.shape (224, 448, 3)\n","219/219 [==============================] - 76s 323ms/step\n","219/219 [==============================] - 77s 322ms/step\n","219/219 [==============================] - 76s 324ms/step\n","219/219 [==============================] - 76s 323ms/step\n","219/219 [==============================] - 77s 324ms/step\n","219/219 [==============================] - 76s 323ms/step\n","219/219 [==============================] - 75s 323ms/step\n","219/219 [==============================] - 75s 322ms/step\n","219/219 [==============================] - 76s 324ms/step\n","219/219 [==============================] - 76s 324ms/step\n","\n","\n","MODEL :  M+_mpf_jpg_PTx8_RtdXall_LowC2_AW1e5D1e4_blos_24\n","FOLDS WITH MODELS:  ['fd000', 'fd001', 'fd002', 'fd003', 'fd004']\n","WARNING : 12 NaN (droped) for label at ts 24\n","------------------------------\n","labels.shape (13317, 1)\n","------------------------------\n","img_size (224, 448, 3)\n","im.shape (224, 448)\n","209/209 [==============================] - 73s 324ms/step\n","209/209 [==============================] - 72s 322ms/step\n","209/209 [==============================] - 72s 323ms/step\n","209/209 [==============================] - 72s 323ms/step\n","209/209 [==============================] - 73s 325ms/step\n","209/209 [==============================] - 72s 323ms/step\n","209/209 [==============================] - 72s 323ms/step\n","209/209 [==============================] - 73s 323ms/step\n","209/209 [==============================] - 74s 325ms/step\n","209/209 [==============================] - 73s 324ms/step\n","CPU times: user 2h 35s, sys: 56min 46s, total: 2h 57min 21s\n","Wall time: 2h 39min\n"]}],"source":["%%time\n","import dill as pickle\n","from pathlib import Path\n","from glob import glob\n","import numpy as np\n","import tensorflow as tf\n","\n","from sundl.utils.data import read_Dataframe_With_Dates\n","from utilsTest import custom_objects_for_model_loading\n","\n","for modelName in modelDict.keys():\n","  # TBR\n","  try:\n","    if modelName.split('_')[2][3] in ['4']:\n","      # TODO : make generic to patch number.\n","      continue\n","  except:\n","    pass\n","\n","  labelCol = modelName.split('_')[1]\n","  h = int(modelName.split('_')[-1])\n","\n","  # #@@@@@@@@\n","  # print('WARNING : Rmv l20  !')\n","  # h=24\n","  # #@@@@@@@@\n","\n","  pathPredFd = F_PATH_PREDS(FOLDER)/f'{modelName}_fd.csv'\n","  pathPredPt = F_PATH_PREDS(FOLDER)/f'{modelName}_pt.csv'\n","  if not pathPredPt.exists():\n","    print('\\n\\nMODEL : ',modelName)\n","\n","    # loading model path and configs for availlable fold models\n","    modelsConfigAndPath = glob((FOLDER/f'models/{modelName}*').as_posix())\n","    modelFoldsPath = [m for m in modelsConfigAndPath if m[-3:]!='pkl']\n","    modelFoldsConfigs = [m for m in modelsConfigAndPath if m[-3:]=='pkl']\n","    # foldIds = [m[-5:] for m in modelFoldsPath]\n","    foldIds = [m.split('/')[-1].split('.')[0][-5:] for m in modelFoldsPath]\n","    n_fold = len(foldIds)\n","    if n_fold == 0:\n","      continue\n","    # for foldIdx in range(n_fold-1,-1,-1):\n","    #   if not Path(f'{modelFoldsPath[foldIdx]}/assets').exists():\n","    #     modelFoldsPath.pop(foldIdx)\n","    #     modelFoldsConfigs.pop(foldIdx)\n","    #     foldIds.pop(foldIdx)\n","    print('FOLDS WITH MODELS: ',foldIds)\n","    if len(foldIds)==0:\n","      continue\n","    with open(modelFoldsConfigs[0], 'rb') as f1:\n","      config = pickle.load(f1)\n","    configTest = config['dataset_val']\n","    dfTest = read_Dataframe_With_Dates(F_PATH_TEST(configTest['labelCol'],configTest['ts_off_label_hours'][0]))\n","    # configTest = config['dataset_val']\n","    configTest['dfTimeseries'] = dfTest.copy()\n","    configTest['samples'] = None\n","    configTest['cache'] = False\n","    configTest['shuffle'] = False\n","    configTest['weightByClass'] = False\n","    configTest['batch_size'] = 64\n","    configTest['epochs'] = 1\n","    # STOP\n","    # encoders consstantss **\n","    classTresholds = configTest['classTresholds']\n","    binCls = modelName[0]\n","    # **\n","    if modelName.split('_')[2] == 'Persistent' and not pathPredPt.exists():\n","      # dsTest , _, _, _ = build_dataset_persistent(**configTest)\n","      # saved pstmod not working\n","      dfId2History =  dfTest.copy()\n","      ts_off_label_hours = h\n","      ts_off_history_hours = -h\n","      dfId2History.index = dfId2History.index.shift(periods = -ts_off_label_hours, freq='H')\n","      input_lag = - ts_off_history_hours\n","      dfId2History['history'] = dfId2History[labelCol].rolling(window = f'{input_lag}H',\n","                                                      closed = 'left', # min_periods = int(input_lag)\n","                                                      ).apply(\n","                                                          lambda x: x[0]) # we remove first month in case of incomplete windows\n","      dfId2History = dfId2History[int(ts_off_label_hours/2):-int(ts_off_label_hours/2)]\n","      dfId2History = dfId2History.copy()\n","\n","      dfId2History['pred'] = dfId2History['history'].apply(lambda x: configTest['labelEncoder'](x))\n","      dfId2History['label'] = dfId2History[labelCol].apply(lambda x: configTest['labelEncoder'](x))\n","      dfPred = dfId2History[[labelCol,'cls','label','pred']].copy()\n","      dfPred.to_csv(pathPredFd)\n","    else:\n","      if 'buildDsFunction' in config.keys():\n","        buildDs = config[f'buildDsFunction']\n","      else:\n","        # default dataset builder if not stored in config (adapt if needed)\n","        buildDs = builDS_image_feature\n","      dsTest , _, missing_file_regexp, dfSamples_corr = buildDs(**configTest)\n","      dfSamples_corr = dfSamples_corr.set_index('timestamp',drop = True)\n","\n","      # predictionss\n","      predsFd = []\n","      patch_predsFd = []\n","      for foldIdx,modelFoldPath in enumerate(modelFoldsPath):\n","        # Full-disk predictions\n","        model = tf.keras.models.load_model(modelFoldPath, compile=False,  custom_objects = custom_objects_for_model_loading)\n","\n","        # STOP\n","        if not pathPredFd.exists():\n","          predsFd.append(model.predict(dsTest))\n","        # Patches predictions\n","        if modelName.split('_')[3][:2] == 'PT':\n","          for layer in model.layers:\n","            if layer.name == 'time_distributed':\n","              patchesBlock = layer\n","          patches = tf.keras.Model(model.input, patchesBlock.output, name='patches')\n","          patch_predsFd.append(patches.predict(dsTest))\n","          # predsFd could be retrieved from it to avoid double computation\n","          del patches\n","        del model\n","      del dsTest\n","\n","      # predictions to dataframes\n","      if not pathPredFd.exists():\n","        dfPred = dfSamples_corr[[f'label_{h}','cls']].copy()\n","        dfPred['label'] = dfPred[f'label_{h}'].apply(lambda x: configTest['labelEncoder'](x))\n","        dfPred['pred'] = np.zeros(len(dfPred))\n","        for idx,foldId in enumerate(foldIds):\n","          dfPred[f'pred_{foldId}'] = predsFd[idx][:,1]\n","          dfPred['pred'] += dfPred[f'pred_{foldId}']\n","        dfPred['pred'] /= (idx+1)\n","        dfPred.to_csv(pathPredFd)\n","\n","      if modelName.split('_')[3][:2] == 'PT':\n","        dfPredPatches = dfSamples_corr[[f'label_{h}','cls']].copy()\n","        dfPredPatches['label'] = dfPredPatches[f'label_{h}'].apply(lambda x: configTest['labelEncoder'](x))\n","        num_ptch = patch_predsFd[0].shape[1]\n","        for ptchId in range(num_ptch):\n","          dfPredPatches[f'pred_pt{ptchId}'] = np.zeros(len(dfPredPatches))\n","          for idx,foldId in enumerate(foldIds):\n","            dfPredPatches[f'pred_pt{ptchId}_{foldId}'] = patch_predsFd[idx][:,ptchId,0]\n","            dfPredPatches[f'pred_pt{ptchId}']  += dfPredPatches[f'pred_pt{ptchId}_{foldId}']\n","          dfPredPatches[f'pred_pt{ptchId}'] /= (idx+1)\n","        dfPredPatches.to_csv(pathPredPt)\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7351,"status":"ok","timestamp":1713548017549,"user":{"displayName":"gregoire francisco","userId":"13749045815358519395"},"user_tz":-120},"id":"9XHs62RNHoCI","outputId":"ec6f22b3-d5b4-47b6-d44a-fe52b0f605dc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ensemble models prediction\n","C+_PCNN_Both_Max False\n","M+_PCNN_Both_Max False\n","C+_PCNN_Both_Avg False\n","M+_PCNN_Both_Avg False\n"]}],"source":["import dill as pickle\n","from pathlib import Path\n","from glob import glob\n","import numpy as np\n","import tensorflow as tf\n","from sundl.utils.data import read_Dataframe_With_Dates\n","print('Ensemble models prediction')\n","for modelName in ensembles.keys():\n","  ensModIsMax = False\n","  if modelName.split('_')[-1] in ['max','Max']:\n","    ensModIsMax = True\n","  pathPredFd =  F_PATH_PREDS(FOLDER)/f'{modelName}_fd.csv'\n","  pathPredPt =  F_PATH_PREDS(FOLDER)/f'{modelName}_pt.csv'\n","  print(modelName,pathPredPt.exists() )\n","  if not pathPredPt.exists():\n","    for pathPred in [pathPredFd,pathPredPt]:\n","      predTag = pathPred.as_posix().split('_')[-1][:2]\n","      for idx,subModelName in enumerate(ensembles[modelName]):\n","        subModel = read_Dataframe_With_Dates(F_PATH_PREDS(FOLDER)/f'{modelDictRev[subModelName]}_{predTag}.csv')\n","        if idx == 0:\n","          dfPred = subModel.copy()\n","          pred_cols = [col for col in dfPred.columns if col[:3]=='pre']\n","          ptcPredCols = [col for col in dfPred.columns if len(col)==len('pred_pt0')]\n","          num_ptc = len(ptcPredCols)\n","        else:\n","          # keeping only common dates\n","          tmp = subModel.copy()\n","          tmp = tmp[tmp.index.isin(dfPred.index)].sort_index()\n","          dfPred = dfPred[dfPred.index.isin(tmp.index)].sort_index()\n","          # averaging\n","          if modelDictRev[subModelName].split('_')[2] == 'Persistent':\n","            # empirical persistent probability\n","            for ptchTag in [''] + [f'_pt{ptcId}' for ptcId in range(num_ptc)]:\n","              c = tmp[f'change{ptchTag}'].sum()\n","              tot = len(tmp)\n","              pChange = c/ (2*tot)\n","              tmp[tmp[f'histo{ptchTag}']==1][f'pred{ptchTag}'] = 1 - pChange # prob of positive event\n","              tmp[tmp[f'histo{ptchTag}']==0][f'pred{ptchTag}'] = pChange # prob of positive event\n","            for col in pred_cols:\n","              if ensModIsMax:\n","                dfPred[col] = np.maximum(dfPred[col],tmp[col])\n","              else:\n","                dfPred[col] = dfPred[col] + tmp[col]\n","          else:\n","            missingCols = [col for col in pred_cols if col not in tmp.columns]\n","            for col in missingCols:\n","              tmp[col] = dfPred[col]\n","            if ensModIsMax:\n","              for col in pred_cols:\n","                dfPred[col] = np.maximum(dfPred[col],tmp[col])\n","            else:\n","              dfPred[pred_cols] = dfPred[pred_cols] + tmp[pred_cols]\n","      if not ensModIsMax:\n","        dfPred[pred_cols] = dfPred[pred_cols]/len(ensembles[modelName])\n","      dfPred = dfPred[['mpf','cls','label']+[col for col in dfPred.columns if col[:3]=='pre']]\n","      dfPred.to_csv(pathPred)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7xUXqp0MWEfX"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":0}
