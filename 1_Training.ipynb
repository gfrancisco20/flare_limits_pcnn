{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training \n",
    "\n",
    "Notebooks to train models  \n",
    "  \n",
    "Examples is given for the EUV PCNNs of the paper    \n",
    "  \n",
    "Results are stored in PATH_RES/CONTINUING_FOLDER   \n",
    "(or PATH_RES/NEW_FOLDER_NAME when creating a new reslult folder)  \n",
    "\n",
    "The structure of a NEW_FOLDER_NAME is   \n",
    "automatically set up by the function utilsTraining.setUpResultFolder,   \n",
    "called here in the begining of the cell 'Training'  \n",
    "The content of those result folders is described in the doc config.py, below 'PATH_RES'  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLAB = True\n",
    "\n",
    "if COLAB : \n",
    "  configSetup = {\n",
    "      'COLAB'           : 'True',\n",
    "      'PATH_ROOT_DRIVE' : '/content/drive/MyDrive/Projects/Forecast',\n",
    "      'PATH_ROOT_LOCAL' : '/content/session',\n",
    "      'PATH_SUNDL'      : '/content/sundl',\n",
    "      'PATH_PROJECT'    : '/content/flare_limits_pcnn'\n",
    "  }\n",
    "  !git clone https://github.com/gfrancisco20/sundl.git\n",
    "  !git clone https://github.com/gfrancisco20/flare_limits_pcnn.git\n",
    "  import sys\n",
    "  import re\n",
    "  sys.path.append(configSetup['PATH_SUNDL'])\n",
    "  sys.path.append(configSetup['PATH_PROJECT'])\n",
    "  configFile = f'{configSetup[\"PATH_PROJECT\"]}/config.py'\n",
    "  with open(configFile, 'r') as file:\n",
    "    content = file.read()\n",
    "  for constant in configSetup.keys():\n",
    "    content = re.sub(re.compile(f'{constant} = .*'), f'{constant} = \\'{configSetup[constant]}\\'', content)\n",
    "  with open(configFile, 'w') as file:\n",
    "    file.write(content)\n",
    "   \n",
    "from config import *\n",
    "if COLAB:\n",
    "  from sundl.utils.colab import mountDrive\n",
    "  # mouting drive content in session on colab\n",
    "  mountDrive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sunpy.net import Fido\n",
    "# from sunpy.net import attrs as a\n",
    "# event_type = \"FL\"\n",
    "# tstart = \"2010/04/28\"\n",
    "# tend = \"2023/04/29\"\n",
    "# result = Fido.search(a.Time(tstart, tend),\n",
    "#                      a.hek.EventType(event_type),\n",
    "#                      a.hek.FL.GOESCls > \"C1.0\",\n",
    "#                      a.hek.OBS.Observatory == \"GOES\")\n",
    "# # Here we only show two columns due there being over 100 columns returned normally.\n",
    "# print(result.show(\"hpc_bbox\", \"refs\"))\n",
    "\n",
    "# # It\"s also possible to access the HEK results from the\n",
    "# # `~sunpy.net.fido_factory.UnifiedResponse` by name.\n",
    "# hek_results = result[\"hek\"]\n",
    "# filtered_results = hek_results[\"event_starttime\", \"event_peaktime\",\n",
    "#                                \"event_endtime\", \"fl_goescls\", \"ar_noaanum\"]\n",
    "\n",
    "# filtered_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-21 13:53:41.989424: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import dill as pickle\n",
    "import shutil\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Not connected to a GPU\n",
      "Your runtime has 17.2 gigabytes of available RAM\n",
      "\n",
      "Not using a high-RAM runtime\n",
      "\n",
      "images files already in local\n",
      "CPU times: user 3.74 ms, sys: 3.32 ms, total: 7.06 ms\n",
      "Wall time: 15.3 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sh: nvidia-smi: command not found\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sundl.utils.colab import mountDrive, ressourcesSetAndCheck, drive2local\n",
    "############################\n",
    "# SETUP\n",
    "############################\n",
    "\n",
    "# overwriting CLEAN_LOCAL :\n",
    "CLEAN_LOCAL = False\n",
    "\n",
    "if CLEAN_LOCAL:\n",
    "  shutil.rmtree(PATH_ROOT_LOCAL)\n",
    "  os.makedirs(PATH_ROOT_LOCAL)\n",
    "  \n",
    "# checking gpu and ram ressources\n",
    "ressourcesSetAndCheck(MIXED_PREC)\n",
    "\n",
    "############################\n",
    "# DATA IMPORT\n",
    "############################\n",
    "\n",
    "FILES2TRANSFER = {'images' : (PATH_ROOT_DRIVE_DS/'Images',        # source\n",
    "                              PATH_IMAGES,                        # dest\n",
    "                              ['png/eq_blos_448']#, 'eq_193x211x94_448'] # files\n",
    "                              )\n",
    "                  }\n",
    "\n",
    "drive2local(FILES2TRANSFER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sundl.metrics.tfmetrics import *\n",
    "\n",
    "\n",
    "labelCol     = 'mpf' # 'mpf' -> windows's SXR-max-peak-flux , 'toteh' -> (hourly average of sum of flares' SXR-fluence)\n",
    "windowSizesH = [24]\n",
    "EPOCHS       = 12 # 25\n",
    "BATCH_SIZE   = 16\n",
    "IMG_SIZE     = (224, 448, 3) # (512, 1024, 3) (224, 448, 3)\n",
    "PTCH_SIZE    = (112, 112, 3) # (256, 256, 3) (112, 112, 3)\n",
    "\n",
    "NEW_FOLDER_NAME   = 'Classification_PCNN'                 # New folder in which to store results\n",
    "CONTINUING_FOLDER = None # Existing foler in which to store results\n",
    "\n",
    "if labelCol=='mpf':\n",
    "  # aggregation type \n",
    "  agg = 'max'\n",
    "else:\n",
    "  agg = 'sum'\n",
    "\n",
    "weightByClass = True\n",
    "\n",
    "CV_K      = 5 \n",
    "VAL_SPLIT = None # --> not used if CV_K not none\n",
    "\n",
    "SAMPLE_TRAIN = None # 0.95 \n",
    "SAMPLE_VAL   = None\n",
    "\n",
    "CACHE     = True\n",
    "verbose   = 0\n",
    "\n",
    "SAVE_MODEL   = True\n",
    "save_monitor = 'val_tss3'\n",
    "save_mode    = 'max'\n",
    "save_thdS    = {'C': 0.50, \n",
    "                'M': 0.25, \n",
    "                'X': 0.10} \n",
    "\n",
    "RECOMPUTE_DATASET = True\n",
    "\n",
    "thresholds = [0.5]\n",
    "metrics = [tf.keras.metrics.BinaryAccuracy(threshold=0.5, name=f'acc')] \\\n",
    "        + [Tss(threshold=thd) for thd in thresholds] \\\n",
    "        + [Hss(threshold=thd) for thd in thresholds] \\\n",
    "        + [Mcc(threshold=thd) for thd in thresholds] \\\n",
    "        + [F1(threshold=thd) for thd in thresholds] \\\n",
    "        + [tf.keras.metrics.Precision(class_id = 1, name = 'precision')] \\\n",
    "        + [tf.keras.metrics.Recall(class_id = 1, name = 'recall')] \\\n",
    "        + [TP(threshold=thd) for thd in thresholds] \\\n",
    "        + [FN(threshold=thd) for thd in thresholds] \\\n",
    "        + [TN(threshold=thd) for thd in thresholds] \\\n",
    "        + [FP(threshold=thd) for thd in thresholds] \\\n",
    "        + [tf.keras.metrics.AUC(curve='ROC', name='auc_roc')] \\\n",
    "        + [tf.keras.metrics.AUC(curve='PR', name='auc_pr')]\n",
    "   \n",
    "# different weights and penalisation strategies  \n",
    "WEIGHT_BY_CLASS = True   \n",
    "weightCollection = {'EquiC'    : {'quiet': 0.25, 'B':0.25, 'C':0.167, 'M':0.167, 'X': 0.166},\n",
    "                    'EquiCnat' : {'quiet': 0.46, 'B':0.54, 'C':0.72, 'M':0.26, 'X': 0.03},\n",
    "                    'EquiM'    : {'quiet': 0.166, 'B':0.167, 'C':0.167, 'M':0.25, 'X': 0.25},\n",
    "                    'EquiMnat' : {'quiet': 0.28, 'B':0.32, 'C':0.40, 'M':0.91, 'X': 0.09},\n",
    "                    'ProgPos'  : {'quiet': 0.05, 'B':0.05, 'C':0.10, 'M':0.30, 'X': 0.50},\n",
    "                    'LowBC'    : {'quiet': 0.4, 'B':0.2, 'C':0.1, 'M':0.8, 'X': 0.8},\n",
    "                    'LowC'     : {'quiet': 0.4, 'B':0.4, 'C':0.1, 'M':0.8, 'X': 0.8},\n",
    "                    'LowC2'    : {'quiet': 0.2, 'B':0.2, 'C':0.1, 'M':0.8, 'X': 0.8} \n",
    "                    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilsTraining import ModelInstantier2\n",
    "from sundl.models.blueprints import build_pretrained_PatchCNN\n",
    "from sundl.dataloader.sdocml import builDS_image_feature\n",
    "from tensorflow.keras.optimizers import Adam, AdamW\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "# Dataset common parameters\n",
    "ds_params = {'labelCol'    : labelCol,\n",
    "             'num_classes' : num_classes,\n",
    "             'img_size'    : IMG_SIZE,\n",
    "             'shiftSamplesByLabelOff' : True,\n",
    "             'encoderIsTf' : False\n",
    "             }\n",
    "\n",
    "# Models common parameters\n",
    "tfModel = tf.keras.applications.efficientnet_v2.EfficientNetV2S\n",
    "core_params = {'tfModel'        : tfModel,\n",
    "               'pretainedWeight': True,\n",
    "               'unfreeze_top_N' : 'all', \n",
    "               'num_classes'    : num_classes, # no use here\n",
    "               'img_size'       : IMG_SIZE,\n",
    "               'patches_size'   : PTCH_SIZE,\n",
    "               'regression'     : False,\n",
    "               'metrics'        : metrics,\n",
    "               'includeInterPatches' : False,\n",
    "               'loss' : BinaryCrossentropy(label_smoothing = 0,\n",
    "                                           name = 'loss'\n",
    "                                         )\n",
    "               } \n",
    "\n",
    "# Models definition\n",
    "# We just give as an example the fina EUV models of the paper\n",
    "PCNN_C =  ModelInstantier2(\n",
    "    buildModelFunction = build_pretrained_PatchCNN,\n",
    "    buildModelParams = dict(**core_params,\n",
    "                            **{'patche_output_type' : 'pre_pred',\n",
    "                               'meth_patche_agg'    : agg,\n",
    "                               'shared_patcher'     : 'all',\n",
    "                               'optimizer'          : AdamW(learning_rate = 1e-5,#  amsgrad = True,\n",
    "                                                            weight_decay  = 1e-4)\n",
    "                              }\n",
    "                            ),\n",
    "    buildDsFunction = builDS_image_feature,\n",
    "    buildDsParams =  ds_params,\n",
    "    name = f'C+_{labelCol}',\n",
    "    cls = 'C',\n",
    "    weightStrategy = 'ProgPos'\n",
    ")\n",
    "\n",
    "PCNN_M =  ModelInstantier2(\n",
    "    buildModelFunction = build_pretrained_PatchCNN,\n",
    "    buildModelParams = dict(**core_params,\n",
    "                            **{'patche_output_type' : 'pre_pred',\n",
    "                               'meth_patche_agg'    : agg,\n",
    "                               'shared_patcher'     : 'all',\n",
    "                               'optimizer'          : AdamW(learning_rate = 1e-5,#  amsgrad = True,\n",
    "                                                            weight_decay  = 1e-4)\n",
    "                              }\n",
    "                            ),\n",
    "    buildDsFunction = builDS_image_feature,\n",
    "    buildDsParams =  ds_params,\n",
    "    name = f'M+_{labelCol}',\n",
    "    cls = 'M',\n",
    "    weightStrategy = 'ProgPos'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INITIAL STATUS : \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C+_mpf_blos_24__PTx8_RtdXall_ProgPos</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M+_mpf_blos_24__PTx8_RtdXall_ProgPos</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      status duration\n",
       "model                                                \n",
       "C+_mpf_blos_24__PTx8_RtdXall_ProgPos       0         \n",
       "M+_mpf_blos_24__PTx8_RtdXall_ProgPos       0         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "minDate :  2010-05-13 00:00:00\n",
      "maxDate :  2023-04-19 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "labelCol :  mpf\n",
      "window_h :  24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/greg/Projects/flare_limits_pcnn/../sundl/sundl/dataloader/sdocml.py:193: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  ).apply(lambda x: x[-1]).shift(freq = f'-{offLabel}H')#[:-int(offLabel/2)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-----------------------------\n",
      "Model : C+_mpf_blos_24__PTx8_RtdXall_ProgPos\n",
      "\n",
      "\n",
      "-----------------------------\n",
      "Model : C+_mpf_blos_24__PTx8_RtdXall_ProgPos\n",
      "FOLD #0\n",
      "WARNING : 12 NaN (droped) for label at ts 24\n",
      "Samples shiiftng done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-21 13:54:04.033250: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "labels.shape (12951, 1)\n",
      "------------------------------\n",
      "labelCol mpf\n",
      "classTresholds {'quiet': (0.0, 1e-07), 'B': (1e-07, 1e-06), 'C': (1e-06, 1e-05), 'M': (1e-05, 0.0001), 'X': (0.0001, inf)}\n",
      "CLASS quiet\n",
      "len(labels) 12951\n",
      "len(labels[clsIdxs]) 3129\n",
      "actualWeights[cls 0.241602965022006\n",
      "CLASS B\n",
      "len(labels) 12951\n",
      "len(labels[clsIdxs]) 3066\n",
      "actualWeights[cls 0.23673847579337504\n",
      "CLASS C\n",
      "len(labels) 12951\n",
      "len(labels[clsIdxs]) 3146\n",
      "actualWeights[cls 0.242915604972589\n",
      "CLASS M\n",
      "len(labels) 12951\n",
      "len(labels[clsIdxs]) 3166\n",
      "actualWeights[cls 0.24445988726739248\n",
      "CLASS X\n",
      "len(labels) 12951\n",
      "len(labels[clsIdxs]) 444\n",
      "actualWeights[cls 0.03428306694463748\n",
      "img_size (224, 448, 3)\n",
      "im.shape (224, 448)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/greg/Projects/flare_limits_pcnn/../sundl/sundl/dataloader/sdocml.py:193: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  ).apply(lambda x: x[-1]).shift(freq = f'-{offLabel}H')#[:-int(offLabel/2)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING : 12 NaN (droped) for label at ts 24\n",
      "Samples shiiftng done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-21 13:54:09.093889: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "labels.shape (1984, 1)\n",
      "------------------------------\n",
      "img_size (224, 448, 3)\n",
      "im.shape (224, 448)\n",
      "293 incomplete training dates\n",
      "15 incomplete val dates\n",
      "\n",
      "MODEL PARAMETERS #: 20.34M\n",
      "of which trainable #: tf.Tensor(20027457, shape=(), dtype=int32)\n",
      "\u001b[1m  3/810\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:39\u001b[0m 7s/step - FN: 0.0000e+00 - FP: 24.0000 - TN: 1.0000 - TP: 7.0000 - acc: 0.2639 - auc_pr: 0.3511 - auc_roc: 0.2214 - f1: 0.3801 - hss: 0.0242 - loss: 0.4268 - mcc: 0.1063 - precision: 0.2351 - recall: 1.0000 - tss: 0.0499  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [05:49<?, ?it/s]\n",
      "  0%|          | 0/2 [05:50<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 165\u001b[0m\n\u001b[1;32m    163\u001b[0m   historyData \u001b[38;5;241m=\u001b[39m trainConstantModel(dsTrain, dsVal, model, modelInstantiater, EPOCHS, weightByClass, SAVE_MODEL, modelDirSub)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m   history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsTrain\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;66;43;03m#.take(1),\u001b[39;49;00m\n\u001b[1;32m    166\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdsVal\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;66;43;03m#.take(1),\u001b[39;49;00m\n\u001b[1;32m    168\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#verbose\u001b[39;49;00m\n\u001b[1;32m    170\u001b[0m \u001b[43m                      \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m   historyData \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory\n\u001b[1;32m    172\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m SAVE_MODEL:\n",
      "File \u001b[0;32m~/Projects/sundl/.conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:118\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Projects/sundl/.conda/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:323\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    322\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 323\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    324\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(\n\u001b[1;32m    325\u001b[0m         step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    326\u001b[0m     )\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/Projects/sundl/.conda/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Projects/sundl/.conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Projects/sundl/.conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/sundl/.conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/sundl/.conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Projects/sundl/.conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/Projects/sundl/.conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/Projects/sundl/.conda/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/Projects/sundl/.conda/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from utilsTraining import setUpResultFolder, conditionalHyperParameters, trainConstantModel, printTrainingResults, saveTrainingResults\n",
    "from sundl.utils.data import read_Dataframe_With_Dates, loadMinMaxDates\n",
    "from sundl.utils.flare.windows import windowHistoryFromFlList\n",
    "\n",
    "models = [(PCNN_C, ['blos'], h) for h in windowSizesH] + \\\n",
    "         [(PCNN_M, ['blos'], h) for h in windowSizesH] \n",
    "\n",
    "log, resDir, modelDir, mtcDict = setUpResultFolder(\n",
    "    models = models, \n",
    "    pathRes = PATH_RES,\n",
    "    metrics = metrics,\n",
    "    continuingFolder = CONTINUING_FOLDER, \n",
    "    newFolder = NEW_FOLDER_NAME,\n",
    "    imgSize = IMG_SIZE,\n",
    "    cv_K = CV_K,\n",
    "    saveModel = SAVE_MODEL\n",
    "    )\n",
    "\n",
    "print('\\nINITIAL STATUS : ')\n",
    "display(log)\n",
    "print('')\n",
    "res = {}\n",
    "best = None\n",
    "eval = None\n",
    "bestCVCrossEpoch = None\n",
    "dsTrain = None\n",
    "dsVal = None\n",
    "ct=0\n",
    "verbose = 1\n",
    "ct_dsBuilds = -1\n",
    "minDate, maxDate = loadMinMaxDates(PATH_IMAGES)\n",
    "flCatalog = read_Dataframe_With_Dates(PATH_FLCATALOG)\n",
    "print('minDate : ', minDate)\n",
    "print('maxDate : ', maxDate)\n",
    "\n",
    "for modelInstantiater, channels, h in tqdm(models):\n",
    "  ct_dsBuilds+=1\n",
    "  \n",
    "  \n",
    "  save_thd, labelCol, binCls, classWeights, classTresholds, encoder = conditionalHyperParameters(modelInstantiater, h, save_thdS, weightCollection)\n",
    "  modelInstantiater.buildDsParams['labelEncoder'] = encoder\n",
    "  modelInstantiater.buildDsParams['classTresholds'] = classTresholds\n",
    "  \n",
    "  if F_PATH_WINDOWS('mpf', h).exists():\n",
    "    dfFlareHistory = read_Dataframe_With_Dates(F_PATH_WINDOWS('mpf', h))\n",
    "  else:\n",
    "    dfFlareHistory = windowHistoryFromFlList(flCatalog, window_h = h, timeRes_h = 2, minDate = minDate, maxDate = maxDate)\n",
    "  \n",
    "  \n",
    "  CV_FLD_PTH  = F_PATH_FOLDS(labelCol, h)\n",
    "  with open(CV_FLD_PTH, 'rb') as f1:\n",
    "    dfFoldsTrainVal = pickle.load(f1)[0:CV_K]\n",
    "    \n",
    "  full_name_comb = modelInstantiater.fullNameFunc(channels,h)\n",
    "  if log.loc[full_name_comb]['status'] > 0:\n",
    "    print(f'\\n\\n-----------------------------\\n{full_name_comb} already successfuly trained\\n')\n",
    "  else:\n",
    "    log.loc[full_name_comb, 'status'] = -1\n",
    "    log.to_csv(resDir + '/log.csv')\n",
    "  \n",
    "    model = None\n",
    "    if RECOMPUTE_DATASET:\n",
    "      dsTrain = None\n",
    "      dsVal = None\n",
    "  \n",
    "    #===================================================\n",
    "    # CROSS VALIDATION LOOP\n",
    "    #===================================================\n",
    "    duration = time.time()\n",
    "    res[full_name_comb] = []\n",
    "    kf=0\n",
    "    for df_train, df_val in tqdm(dfFoldsTrainVal,disable = False):#not verbose):\n",
    "      print(f'\\n\\n-----------------------------\\nModel : {full_name_comb}')\n",
    "      if Path(resDir+f'/training_folds/training_{full_name_comb}_fd{kf:0>3d}.csv').exists():\n",
    "        res[full_name_comb].append(pd.read_csv(resDir+f'/training_folds/training_{full_name_comb}_fd{kf:0>3d}.csv').set_index('epoch'))\n",
    "        print(f'FOLD #{kf} ALREADY TRAINED')\n",
    "        kf += 1\n",
    "      else:\n",
    "        print(f'\\n\\n-----------------------------\\nModel : {full_name_comb}')\n",
    "        print(f'FOLD #{kf}')\n",
    "        \n",
    "        # MEMORY CLEANING\n",
    "        tf.keras.backend.clear_session()\n",
    "        tf.compat.v1.reset_default_graph()\n",
    "        if model is not None: del model\n",
    "        if RECOMPUTE_DATASET:\n",
    "          if dsTrain is not None: del dsTrain\n",
    "          if dsVal is not None: del dsVal\n",
    "        gc.collect()\n",
    "        \n",
    "        # FOLDER FOR MODEL\n",
    "        if SAVE_MODEL:\n",
    "          modelDirSub = modelDir + f'/{full_name_comb}'\n",
    "          if CV_K is not None:\n",
    "            modelDirSub = modelDirSub + f'_fd{kf:0>3d}'\n",
    "          modelDirSub += '.keras'\n",
    "            \n",
    "        # DATASETS INSTANTIATION \n",
    "        dfSamples_train = df_train.copy()\n",
    "        dfSamples_val = df_val.copy()\n",
    "        if SAMPLE_TRAIN is not None:\n",
    "          dfSamples_train = dfSamples_train.sample(frac = SAMPLE_TRAIN, random_state=49)\n",
    "        if SAMPLE_VAL is not None:\n",
    "           dfSamples_val = dfSamples_val.sample(frac = SAMPLE_VAL, random_state=49)\n",
    "        if ct_dsBuilds==0 or RECOMPUTE_DATASET:\n",
    "          pathDir = PATH_IMAGES if channels is not None else None\n",
    "          dsTrain, _, missing_file_regexp, dfSamples_train_corr = modelInstantiater.build_DS(\n",
    "              pathDir    = pathDir,\n",
    "              channels   = channels,\n",
    "              dfTimeseries = dfFlareHistory.copy(), \n",
    "              samples    = dfSamples_train.copy(), \n",
    "              ts_off_label_hours = [h],\n",
    "              batch_size = BATCH_SIZE,\n",
    "              epochs     = EPOCHS,\n",
    "              cache      = CACHE,\n",
    "              shuffle    = True,\n",
    "              weightByClass = WEIGHT_BY_CLASS,\n",
    "              classWeights = classWeights,\n",
    "          )\n",
    "          print('')\n",
    "          dsVal, _, missing_file_regexp_val, dfSamples_val_corr  = modelInstantiater.build_DS(\n",
    "              pathDir    = pathDir,\n",
    "              channels   = channels,\n",
    "              dfTimeseries = dfFlareHistory.copy(),\n",
    "              samples    = dfSamples_val.copy(),\n",
    "              ts_off_label_hours = [h],\n",
    "              batch_size = BATCH_SIZE,\n",
    "              epochs     = EPOCHS,\n",
    "              cache      = CACHE,\n",
    "              shuffle    = True,\n",
    "              weightByClass = False,\n",
    "              classWeights = None,\n",
    "              typeDs = 'val'\n",
    "          )\n",
    "          print(f'{len(missing_file_regexp)} incomplete training dates')\n",
    "          print(f'{len(missing_file_regexp_val)} incomplete val dates')\n",
    "          \n",
    "        # MODEL INSTANTIATION\n",
    "        model = modelInstantiater()\n",
    "        try:\n",
    "          print(f'\\nMODEL PARAMETERS #: {model.count_params()/1e6:.2f}M')\n",
    "          trainable_params = tf.reduce_sum([tf.reduce_prod(p.shape) for p in model.trainable_variables])\n",
    "          print(\"of which trainable #:\", trainable_params)\n",
    "        except:\n",
    "          pass\n",
    "        \n",
    "        # CALLBACKS\n",
    "        callbacks = []\n",
    "        if SAVE_MODEL:\n",
    "          callbacks.append(tf.keras.callbacks.ModelCheckpoint(\n",
    "              modelDirSub,\n",
    "              save_best_only = True,\n",
    "              save_weights_only=False,\n",
    "              monitor = save_monitor,\n",
    "              verbose = 1,\n",
    "              mode = save_mode,\n",
    "              initial_value_threshold = save_thd)\n",
    "          )\n",
    "        \n",
    "        # TRAINING\n",
    "        if modelInstantiater.savedPredictionModel:\n",
    "          # models where input = output (e.g. persistant models)\n",
    "          historyData = trainConstantModel(dsTrain, dsVal, model, modelInstantiater, EPOCHS, weightByClass, SAVE_MODEL, modelDirSub)\n",
    "        else:\n",
    "          history = model.fit(dsTrain,#.take(1),\n",
    "                              epochs=EPOCHS,\n",
    "                              validation_data = dsVal,#.take(1),\n",
    "                              callbacks = callbacks,\n",
    "                              verbose = 1 #verbose\n",
    "                              )\n",
    "          historyData = history.history\n",
    "          if SAVE_MODEL:\n",
    "            pathConfigModel = modelDirSub + f'_config.pkl'\n",
    "            modelInstantiater.saveConfig(pathConfigModel)\n",
    "        # vectorizing metric reesults\n",
    "        historyData = {m : np.array(historyData[m]) for m in historyData.keys()}\n",
    "        \n",
    "        # ADDITIONAL METRIC\n",
    "        historyData['far'] = 1 - historyData['precision']\n",
    "        historyData['val_far'] = 1 - historyData['val_precision']\n",
    "          \n",
    "        # PRINTING TRAINING HISTORY\n",
    "        printTrainingResults(historyData)\n",
    "\n",
    "        # SAVING FOLD RESULTS\n",
    "        res[full_name_comb].append(pd.DataFrame(historyData)) \n",
    "        res[full_name_comb][-1].index.names = ['epoch']\n",
    "        num_inst = len(dfSamples_train)\n",
    "        res[full_name_comb][-1]['num_train_inst'] = (res[full_name_comb][-1].index + 1) * num_inst\n",
    "        res[full_name_comb][-1].to_csv(resDir+f'/training_folds/training_{full_name_comb}_fd{kf:0>3d}.csv',index=True)\n",
    "        kf+=1 # fold index\n",
    "       \n",
    "      \n",
    "      # END OF CV-LOOP\n",
    "      #===================================================\n",
    "      \n",
    "    # SAVING GENERAL RESULTS\n",
    "    res, best, bestCVCrossEpoch = saveTrainingResults(resDir, res, best, bestCVCrossEpoch, full_name_comb, CV_K)\n",
    "    \n",
    "    duration = time.time() - duration\n",
    "    log.loc[full_name_comb, 'status'] = 1\n",
    "    log.loc[full_name_comb, 'duration'] = f'{duration//3600:0>2.0f}h {duration//60%60:0>2.0f}m {duration%60:0>2.0f}s'\n",
    "    log.to_csv(resDir + '/log.csv')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"PremadePatchConv\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"PremadePatchConv\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ extract_patches__l… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Extract_patches_L…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">37632</span>)            │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ extract_patches_… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)           │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_distributed    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">20,337,761</span> │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ time_distributed… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item_1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ time_distributed… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item_2          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ time_distributed… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item_3          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ time_distributed… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item_4          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ time_distributed… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item_5          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ time_distributed… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item_6          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ time_distributed… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item_7          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ time_distributed… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ maximum (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Maximum</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ get_item[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ get_item_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ get_item_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ get_item_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ get_item_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ get_item_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ get_item_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ get_item_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ subtract (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Subtract</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ maximum[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ subtract[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ maximum[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m448\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│                     │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ extract_patches__l… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m4\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mExtract_patches_L…\u001b[0m │ \u001b[38;5;34m37632\u001b[0m)            │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m112\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ extract_patches_… │\n",
       "│                     │ \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m3\u001b[0m)           │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_distributed    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │ \u001b[38;5;34m20,337,761\u001b[0m │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item (\u001b[38;5;33mGetItem\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ time_distributed… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item_1          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ time_distributed… │\n",
       "│ (\u001b[38;5;33mGetItem\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item_2          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ time_distributed… │\n",
       "│ (\u001b[38;5;33mGetItem\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item_3          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ time_distributed… │\n",
       "│ (\u001b[38;5;33mGetItem\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item_4          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ time_distributed… │\n",
       "│ (\u001b[38;5;33mGetItem\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item_5          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ time_distributed… │\n",
       "│ (\u001b[38;5;33mGetItem\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item_6          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ time_distributed… │\n",
       "│ (\u001b[38;5;33mGetItem\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item_7          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ time_distributed… │\n",
       "│ (\u001b[38;5;33mGetItem\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ maximum (\u001b[38;5;33mMaximum\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ get_item[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ get_item_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ get_item_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ get_item_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ get_item_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ get_item_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ get_item_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ get_item_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ subtract (\u001b[38;5;33mSubtract\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ maximum[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ subtract[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ maximum[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">60,392,677</span> (230.38 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m60,392,677\u001b[0m (230.38 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,027,457</span> (76.40 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,027,457\u001b[0m (76.40 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">310,304</span> (1.18 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m310,304\u001b[0m (1.18 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,054,916</span> (152.80 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m40,054,916\u001b[0m (152.80 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " fileId = '20120106_0400'\n",
    " chan = 'blos'\n",
    " tf.strings.join([pathDir.as_posix(),'/*/',fileId,'_',str(chan),'.*']).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "glob.glob('/Users/greg/session/images/*/2012/01/06/20120106_0400_blos.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob('/Users/greg/session/images/*/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
